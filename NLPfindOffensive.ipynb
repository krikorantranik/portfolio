{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOX1JhTj7YTy43E4VK7pyKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krikorantranik/Work/blob/main/NLPfindOffensive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a great example of how ML can be used for the greater good.\n",
        "\n",
        "In this exercise, I will combine NLP (Doc2Vec) with binary classification to extract offensive and hate language from a set of tweets.\n",
        "\n",
        "Doc2Vec is chosen in this case because it is not pretrained, so it does not rely on a previously provided vocabulary (who knows what we might find... and the tweets are filled with typos, etc). Doc2Vec is a good tool because: 1) as I say does not rely on pre-defined vocabulary and 2) it is a \"complete\" model, it considers the word in the context of its sentence, gives more accurate results than simpler vectorization tools like TF-IDF."
      ],
      "metadata": {
        "id": "39Mz1gDu0QGl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao43jwnMrpPS",
        "outputId": "19184c0d-8ceb-4c13-cdf3-6572a555c8c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "pd.options.mode.chained_assignment = None\n",
        "from io import StringIO\n",
        "from html.parser import HTMLParser\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltkstop = stopwords.words('english')\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "nltk.download('punkt')\n",
        "snow = SnowballStemmer(language='english')\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.utils import resample\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have uploaded two datasets, one with a list of possibly offensive tweets and another with a list of generic tweets, with them I build the dataset to study.\n",
        "\n",
        "Also, I am uploading several datasets that I use to clean the data from words that bring no or generic meaning like place names, personal names, etc."
      ],
      "metadata": {
        "id": "zBtDKRITbQZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maindataset = pd.read_csv(\"labeled_data.csv\")\n",
        "maindataset2 = pd.read_csv(\"twitter_dataset.csv\", encoding = \"ISO-8859-1\")\n",
        "\n",
        "countries = pd.read_json(\"countries.json\")\n",
        "countries[\"country\"] = countries[\"country\"].str.lower()\n",
        "countries = pd.DataFrame(countries[\"country\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "countries.columns = ['word']\n",
        "countries[\"replacement\"] = \"xcountryx\"\n",
        "\n",
        "provincies = pd.read_csv(\"countries_provincies.csv\")\n",
        "provincies1 = provincies[[\"name\"]]\n",
        "provincies1[\"name\"] = provincies1[\"name\"].str.lower()\n",
        "provincies1 = pd.DataFrame(provincies1[\"name\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "provincies1.columns = ['word']\n",
        "provincies1[\"replacement\"] = \"xprovincex\"\n",
        "provincies2 = provincies[[\"name_alt\"]]\n",
        "provincies2[\"name_alt\"] = provincies2[\"name_alt\"].str.lower()\n",
        "provincies2 = pd.DataFrame(provincies2[\"name_alt\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "provincies2.columns = ['word']\n",
        "provincies2[\"replacement\"] = \"xprovincex\"\n",
        "provincies3 = provincies[[\"type_en\"]]\n",
        "provincies3[\"type_en\"] = provincies3[\"type_en\"].str.lower()\n",
        "provincies3 = pd.DataFrame(provincies3[\"type_en\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "provincies3.columns = ['word']\n",
        "provincies3[\"replacement\"] = \"xsubdivisionx\"\n",
        "provincies4 = provincies[[\"admin\"]]\n",
        "provincies4[\"admin\"] = provincies4[\"admin\"].str.lower()\n",
        "provincies4 = pd.DataFrame(provincies4[\"admin\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "provincies4.columns = ['word']\n",
        "provincies4[\"replacement\"] = \"xcountryx\"\n",
        "provincies5 = provincies[[\"geonunit\"]]\n",
        "provincies5[\"geonunit\"] = provincies5[\"geonunit\"].str.lower()\n",
        "provincies5 = pd.DataFrame(provincies5[\"geonunit\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "provincies5.columns = ['word']\n",
        "provincies5[\"replacement\"] = \"xcountryx\"\n",
        "provincies6 = provincies[[\"gn_name\"]]\n",
        "provincies6[\"gn_name\"] = provincies6[\"gn_name\"].str.lower()\n",
        "provincies6 = pd.DataFrame(provincies6[\"gn_name\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "provincies6.columns = ['word']\n",
        "provincies6[\"replacement\"] = \"xcountryx\"\n",
        "provincies = pd.concat([provincies1,provincies2,provincies3,provincies4,provincies5,provincies6], axis=0, ignore_index=True)\n",
        "\n",
        "currencies = pd.read_json(\"country-by-currency-name.json\")\n",
        "currencies1 = currencies[[\"country\"]]\n",
        "currencies1[\"country\"] = currencies1[\"country\"].str.lower()\n",
        "currencies1 = pd.DataFrame(currencies1[\"country\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "currencies1.columns = ['word']\n",
        "currencies1[\"replacement\"] = \"xcountryx\"\n",
        "currencies2 = currencies[[\"currency_name\"]]\n",
        "currencies2[\"currency_name\"] = currencies2[\"currency_name\"].str.lower()\n",
        "currencies2 = pd.DataFrame(currencies2[\"currency_name\"].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "currencies2.columns = ['word']\n",
        "currencies2[\"replacement\"] = \"xcurrencyx\"\n",
        "currencies = pd.concat([currencies1,currencies2], axis=0, ignore_index=True)\n",
        "\n",
        "firstnames = pd.read_csv(\"interall.csv\", header=None)\n",
        "firstnames = firstnames[firstnames[1]>=10000]\n",
        "firstnames = firstnames[[0]]\n",
        "firstnames[0] = firstnames[0].str.lower()\n",
        "firstnames = pd.DataFrame(firstnames[0].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "firstnames.columns = ['word']\n",
        "firstnames[\"replacement\"] = \"xfirstnamex\"\n",
        "\n",
        "lastnames = pd.read_csv(\"intersurnames.csv\", header=None)\n",
        "lastnames = lastnames[lastnames[1]>=10000]\n",
        "lastnames = lastnames[[0]]\n",
        "lastnames[0] = lastnames[0].str.lower()\n",
        "lastnames = pd.DataFrame(lastnames[0].apply(lambda x: str(x).replace('-',' ').replace('.',' ').replace('_',' ').replace(',',' ').replace(':',' ').split(\" \")).explode())\n",
        "lastnames.columns = ['word']\n",
        "lastnames[\"replacement\"] = \"xlastnamex\"\n",
        "\n",
        "temporaldata = pd.read_csv(\"temporal.csv\")\n",
        "\n",
        "dictionary = pd.concat([lastnames,temporaldata,firstnames,currencies,provincies,countries], axis=0, ignore_index=True)\n",
        "dictionary = dictionary.groupby([\"word\"]).first().reset_index(drop=False)\n",
        "dictionary = dictionary.dropna()\n",
        "\n",
        "maindataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "1JdJVOIUs_Ri",
        "outputId": "9cc87347-586f-4b91-9e84-46066e3f8bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
              "0               0      3            0                   0        3      2   \n",
              "1               1      3            0                   3        0      1   \n",
              "2               2      3            0                   3        0      1   \n",
              "3               3      3            0                   2        1      1   \n",
              "4               4      6            0                   6        0      1   \n",
              "...           ...    ...          ...                 ...      ...    ...   \n",
              "24778       25291      3            0                   2        1      1   \n",
              "24779       25292      3            0                   1        2      2   \n",
              "24780       25294      3            0                   3        0      1   \n",
              "24781       25295      6            0                   6        0      1   \n",
              "24782       25296      3            0                   0        3      2   \n",
              "\n",
              "                                                   tweet  \n",
              "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
              "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
              "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
              "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
              "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
              "...                                                  ...  \n",
              "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
              "24779  you've gone and broke the wrong heart baby, an...  \n",
              "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
              "24781              youu got wild bitches tellin you lies  \n",
              "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
              "\n",
              "[24783 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8fea3fdb-1f60-451b-a47d-409e578a8688\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>25291</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>25292</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>25294</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>25295</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>25296</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fea3fdb-1f60-451b-a47d-409e578a8688')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8fea3fdb-1f60-451b-a47d-409e578a8688 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8fea3fdb-1f60-451b-a47d-409e578a8688');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e9df14eb-c297-47cc-90c2-f6b4e9e27b7a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e9df14eb-c297-47cc-90c2-f6b4e9e27b7a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e9df14eb-c297-47cc-90c2-f6b4e9e27b7a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It might be necessary to understand a little the data. From Kaggle:\n",
        "\n",
        "count\n",
        "number of CrowdFlower users who coded each tweet (min is 3, sometimes more users coded a tweet when judgments were determined to be unreliable by CF)\n",
        "\n",
        "hate_speech\n",
        "number of CF users who judged the tweet to be hate speech\n",
        "\n",
        "offensive_language\n",
        "number of CF users who judged the tweet to be offensive\n",
        "\n",
        "neither\n",
        "number of CF users who judged the tweet to be neither offensive nor non-offensive\n",
        "\n",
        "class\n",
        "class label for majority of CF users. 0 - hate speech 1 - offensive language 2 - neither\n",
        "\n",
        "With that, I will filter out the column for class and keep only two, if at least one user flag the tweet as offensive or hate speech then it is."
      ],
      "metadata": {
        "id": "OQOwMDREt3Wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maindataset['hate_speech'] = np.where(maindataset['hate_speech']>0,1,0)\n",
        "maindataset['offensive_language'] = np.where(maindataset['offensive_language']>0,1,0)\n",
        "\n",
        "maindataset = maindataset[['hate_speech',\t'offensive_language', 'tweet']]\n",
        "maindataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Suo-aI_ltsSd",
        "outputId": "a69a79e9-16a0-4526-c88f-9fbe758e6dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       hate_speech  offensive_language  \\\n",
              "0                0                   0   \n",
              "1                0                   1   \n",
              "2                0                   1   \n",
              "3                0                   1   \n",
              "4                0                   1   \n",
              "...            ...                 ...   \n",
              "24778            0                   1   \n",
              "24779            0                   1   \n",
              "24780            0                   1   \n",
              "24781            0                   1   \n",
              "24782            0                   0   \n",
              "\n",
              "                                                   tweet  \n",
              "0      !!! RT @mayasolovely: As a woman you shouldn't...  \n",
              "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
              "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
              "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
              "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n",
              "...                                                  ...  \n",
              "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n",
              "24779  you've gone and broke the wrong heart baby, an...  \n",
              "24780  young buck wanna eat!!.. dat nigguh like I ain...  \n",
              "24781              youu got wild bitches tellin you lies  \n",
              "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n",
              "\n",
              "[24783 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3f905551-1f66-4514-bca2-38dddb133842\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24778</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>you's a muthaf***in lie &amp;#8220;@LifeAsKing: @2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24779</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>you've gone and broke the wrong heart baby, an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24780</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>young buck wanna eat!!.. dat nigguh like I ain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24781</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>youu got wild bitches tellin you lies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24782</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>~~Ruffled | Ntac Eileen Dahlia - Beautiful col...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24783 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f905551-1f66-4514-bca2-38dddb133842')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3f905551-1f66-4514-bca2-38dddb133842 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3f905551-1f66-4514-bca2-38dddb133842');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5abcc7b4-1547-4509-86d6-322e26a9e4ab\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5abcc7b4-1547-4509-86d6-322e26a9e4ab')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5abcc7b4-1547-4509-86d6-322e26a9e4ab button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll prepare the other dataset (with the clean tweets)"
      ],
      "metadata": {
        "id": "e4EB7FsUdKT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maindataset2 = maindataset2[['text']]\n",
        "maindataset2.columns = ['tweet']\n",
        "maindataset2['hate_speech'] = 0\n",
        "maindataset2['offensive_language'] = 0\n",
        "maindataset2 = maindataset2[['hate_speech','offensive_language','tweet']]\n",
        "maindataset = pd.concat([maindataset,maindataset2], ignore_index=True)\n",
        "maindataset.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BY1Zti3YdNCM",
        "outputId": "974cc221-b6a4-4724-bfcf-294352d74d76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        hate_speech  offensive_language\n",
              "count  44833.000000        44833.000000\n",
              "mean       0.111369            0.475275\n",
              "std        0.314592            0.499394\n",
              "min        0.000000            0.000000\n",
              "25%        0.000000            0.000000\n",
              "50%        0.000000            0.000000\n",
              "75%        0.000000            1.000000\n",
              "max        1.000000            1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f96abb2-bd53-475b-8ffb-6b42a5e68e1c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>44833.000000</td>\n",
              "      <td>44833.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.111369</td>\n",
              "      <td>0.475275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.314592</td>\n",
              "      <td>0.499394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f96abb2-bd53-475b-8ffb-6b42a5e68e1c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f96abb2-bd53-475b-8ffb-6b42a5e68e1c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f96abb2-bd53-475b-8ffb-6b42a5e68e1c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0ef40fee-84f0-4d9d-8b20-6f5650c465e4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ef40fee-84f0-4d9d-8b20-6f5650c465e4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0ef40fee-84f0-4d9d-8b20-6f5650c465e4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions used to clean text:\n",
        "\n",
        "1) Strip HTML tags\n",
        "2) Replace words using the dictionay crafted above\n",
        "3) Remove punctuation, double spaces, etc."
      ],
      "metadata": {
        "id": "U19uMf3YvOZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLStripper(HTMLParser):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.reset()\n",
        "        self.strict = False\n",
        "        self.convert_charrefs= True\n",
        "        self.text = StringIO()\n",
        "    def handle_data(self, d):\n",
        "        self.text.write(d)\n",
        "    def get_data(self):\n",
        "        return self.text.getvalue()\n",
        "\n",
        "def strip_tags(html):\n",
        "    s = MLStripper()\n",
        "    s.feed(html)\n",
        "    return s.get_data()\n",
        "\n",
        "def replace_words(tt, lookp_dict):\n",
        " temp = tt.split()\n",
        " res = []\n",
        " for wrd in temp:\n",
        "  res.append(lookp_dict.get(wrd, wrd))\n",
        " res = ' '.join(res)\n",
        " return res\n",
        "\n",
        "def preprepare(eingang):\n",
        " ausgang = strip_tags(eingang)\n",
        " ausgang = eingang.lower()\n",
        " ausgang = ausgang.replace(u'\\xa0', u' ')\n",
        " ausgang = re.sub(r'^\\s*$',' ',str(ausgang))\n",
        " ausgang = ausgang.replace('|', ' ')\n",
        " ausgang = ausgang.replace('ï', ' ')\n",
        " ausgang = ausgang.replace('»', ' ')\n",
        " ausgang = ausgang.replace('¿', '. ')\n",
        " ausgang = ausgang.replace('ï»¿', ' ')\n",
        " ausgang = ausgang.replace('\"', ' ')\n",
        " ausgang = ausgang.replace(\"'\", \" \")\n",
        " ausgang = ausgang.replace('?', ' ')\n",
        " ausgang = ausgang.replace('!', ' ')\n",
        " ausgang = ausgang.replace(',', ' ')\n",
        " ausgang = ausgang.replace(';', ' ')\n",
        " ausgang = ausgang.replace('.', ' ')\n",
        " ausgang = ausgang.replace(\"(\", \" \")\n",
        " ausgang = ausgang.replace(\")\", \" \")\n",
        " ausgang = ausgang.replace(\"{\", \" \")\n",
        " ausgang = ausgang.replace(\"}\", \" \")\n",
        " ausgang = ausgang.replace(\"[\", \" \")\n",
        " ausgang = ausgang.replace(\"]\", \" \")\n",
        " ausgang = ausgang.replace(\"~\", \" \")\n",
        " ausgang = ausgang.replace(\"@\", \" \")\n",
        " ausgang = ausgang.replace(\"#\", \" \")\n",
        " ausgang = ausgang.replace(\"$\", \" \")\n",
        " ausgang = ausgang.replace(\"%\", \" \")\n",
        " ausgang = ausgang.replace(\"^\", \" \")\n",
        " ausgang = ausgang.replace(\"&\", \" \")\n",
        " ausgang = ausgang.replace(\"*\", \" \")\n",
        " ausgang = ausgang.replace(\"<\", \" \")\n",
        " ausgang = ausgang.replace(\">\", \" \")\n",
        " ausgang = ausgang.replace(\"/\", \" \")\n",
        " ausgang = ausgang.replace(\"\\\\\", \" \")\n",
        " ausgang = ausgang.replace(\"`\", \" \")\n",
        " ausgang = ausgang.replace(\"+\", \" \")\n",
        " ausgang = ausgang.replace(\"=\", \" \")\n",
        " ausgang = ausgang.replace(\"_\", \" \")\n",
        " ausgang = ausgang.replace(\"-\", \" \")\n",
        " ausgang = ausgang.replace(':', ' ')\n",
        " ausgang = ausgang.replace('\\n', ' ').replace('\\r', ' ')\n",
        " ausgang = ausgang.replace(\" +\", \" \")\n",
        " ausgang = ausgang.replace(\" +\", \" \")\n",
        " ausgang = ausgang.replace('?', ' ')\n",
        " ausgang = re.sub('[^a-zA-Z]', ' ', ausgang)\n",
        " ausgang = re.sub(' +', ' ', ausgang)\n",
        " ausgang = re.sub('\\ +', ' ', ausgang)\n",
        " ausgang = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', ausgang)\n",
        " return ausgang\n"
      ],
      "metadata": {
        "id": "aA9betKwvUoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clean up the dictionary data"
      ],
      "metadata": {
        "id": "OINgGTm_vW8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary[\"word\"] = dictionary[\"word\"].apply(lambda x: preprepare(x))\n",
        "dictionary = dictionary[dictionary[\"word\"] != \" \"]\n",
        "dictionary = dictionary[dictionary[\"word\"] != \"\"]\n",
        "dictionary = {row['word']: row['replacement'] for index, row in dictionary.iterrows()}"
      ],
      "metadata": {
        "id": "7tU6VA-QvaLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparation of the text data to convert: created a new column with the cleaned version of the text. This is what will be converted to vectors. Then I replace the stopwords and words in the dictionary"
      ],
      "metadata": {
        "id": "uwuqPmg3vcva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maindataset[\"NLPtext\"] = maindataset[\"tweet\"]\n",
        "maindataset[\"NLPtext\"] = maindataset[\"NLPtext\"].str.lower()\n",
        "maindataset[\"NLPtext\"] = maindataset[\"NLPtext\"].apply(lambda x: preprepare(str(x)))\n",
        "maindataset[\"NLPtext\"] = maindataset[\"NLPtext\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (nltkstop)]))\n",
        "maindataset[\"NLPtext\"] = maindataset[\"NLPtext\"].apply(lambda x: replace_words(str(x), dictionary))"
      ],
      "metadata": {
        "id": "syEHxGSJvlN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last part of preparing the text is stemming (make \"studies\"=\"study\"). This is done in this case, since anyways I am training the model from scratch. I do this because it is likely that some of the offensive language is not even in pre-trained models"
      ],
      "metadata": {
        "id": "LlEpMRBzvv1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def steming(sentence):\n",
        " words = word_tokenize(sentence)\n",
        " singles = [snow.stem(plural) for plural in words]\n",
        " oup = ' '.join(singles)\n",
        " return oup\n",
        "\n",
        "maindataset[\"NLPtext\"] = maindataset[\"NLPtext\"].apply(lambda x: steming(x))\n",
        "maindataset['lentweet'] = maindataset[\"tweet\"].apply(lambda x: len(str(x).split(' ')))\n",
        "maindataset = maindataset[maindataset['NLPtext'].notna()]\n",
        "maindataset = maindataset[maindataset['lentweet']>=3]\n",
        "maindataset = maindataset.reset_index(drop=False)\n",
        "maindataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "l8wSpJ3gv7XA",
        "outputId": "07c2302a-adf4-40bb-d4a7-67bdd7ab02aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       index  hate_speech  offensive_language  \\\n",
              "0          0            0                   0   \n",
              "1          1            0                   1   \n",
              "2          2            0                   1   \n",
              "3          3            0                   1   \n",
              "4          4            0                   1   \n",
              "...      ...          ...                 ...   \n",
              "44595  44828            0                   0   \n",
              "44596  44829            0                   0   \n",
              "44597  44830            0                   0   \n",
              "44598  44831            0                   0   \n",
              "44599  44832            0                   0   \n",
              "\n",
              "                                                   tweet  \\\n",
              "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
              "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
              "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
              "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
              "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
              "...                                                  ...   \n",
              "44595  @lookupondeath ...Fine, and I'll drink tea too...   \n",
              "44596  Greg Hardy you a good player and all but don't...   \n",
              "44597  You can miss people and still never want to se...   \n",
              "44598  @bitemyapp i had noticed your tendency to pee ...   \n",
              "44599  I think for my APUSH creative project I'm goin...   \n",
              "\n",
              "                                                 NLPtext  lentweet  \n",
              "0      rt mayasolov woman complain clean xlastnamex a...        25  \n",
              "1      rt mleew boy dat cold tyga dwn bad cuffin dat ...        16  \n",
              "2      rt urkindofbrand dawg rt sbabi life ever fuck ...        21  \n",
              "3      rt xprovincex xprovincex xlastnamex viva base ...         9  \n",
              "4      rt shenikarobert shit hear might xlastnamex mi...        26  \n",
              "...                                                  ...       ...  \n",
              "44595  lookupondeath xlastnamex drink xfirstnamex xla...        10  \n",
              "44596  xfirstnamex xlastnamex xlastnamex player get f...        21  \n",
              "44597   miss xprovincex xlastnamex never want xlastnamex        12  \n",
              "44598  bitemyapp notic tendenc pee carpet want say an...        19  \n",
              "44599  think apush creativ project go bring xlastname...        21  \n",
              "\n",
              "[44600 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-844995cc-18a8-4539-9284-d9ff3b7496f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>tweet</th>\n",
              "      <th>NLPtext</th>\n",
              "      <th>lentweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "      <td>rt mayasolov woman complain clean xlastnamex a...</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "      <td>rt mleew boy dat cold tyga dwn bad cuffin dat ...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "      <td>rt urkindofbrand dawg rt sbabi life ever fuck ...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "      <td>rt xprovincex xprovincex xlastnamex viva base ...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "      <td>rt shenikarobert shit hear might xlastnamex mi...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44595</th>\n",
              "      <td>44828</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@lookupondeath ...Fine, and I'll drink tea too...</td>\n",
              "      <td>lookupondeath xlastnamex drink xfirstnamex xla...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44596</th>\n",
              "      <td>44829</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Greg Hardy you a good player and all but don't...</td>\n",
              "      <td>xfirstnamex xlastnamex xlastnamex player get f...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44597</th>\n",
              "      <td>44830</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>You can miss people and still never want to se...</td>\n",
              "      <td>miss xprovincex xlastnamex never want xlastnamex</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44598</th>\n",
              "      <td>44831</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>@bitemyapp i had noticed your tendency to pee ...</td>\n",
              "      <td>bitemyapp notic tendenc pee carpet want say an...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44599</th>\n",
              "      <td>44832</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I think for my APUSH creative project I'm goin...</td>\n",
              "      <td>think apush creativ project go bring xlastname...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44600 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-844995cc-18a8-4539-9284-d9ff3b7496f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-844995cc-18a8-4539-9284-d9ff3b7496f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-844995cc-18a8-4539-9284-d9ff3b7496f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f4906655-e563-4058-a201-c3e8dc967287\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4906655-e563-4058-a201-c3e8dc967287')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f4906655-e563-4058-a201-c3e8dc967287 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "C774PP1dwYTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = maindataset.sample(frac=1).reset_index(drop=True)\n",
        "trainset = trainset[(trainset['NLPtext'].str.len() >= 3)]\n",
        "trainset = trainset.sample(frac=1).reset_index(drop=True)\n",
        "trainset = trainset[[\"NLPtext\"]]\n",
        "\n",
        "tagged_data = []\n",
        "for index, row in trainset.iterrows():\n",
        " part = TaggedDocument(words=word_tokenize(row[0]), tags=[str(index)])\n",
        " tagged_data.append(part)\n",
        "model = Doc2Vec(vector_size=350, min_count=3, epochs=50, window=10, dm=1)\n",
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
        "model.save(\"d2v.model\")\n",
        "print(\"Model Saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oc3LnqpwZBa",
        "outputId": "603b95e1-6b5f-47b8-bf66-f0bba0f55e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vetorize the tweets (convert text to numbers)"
      ],
      "metadata": {
        "id": "GKKECzMDwiMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = []\n",
        "for index, row in maindataset.iterrows():\n",
        " nlptext = row['NLPtext']\n",
        " ids = row['index']\n",
        " vector = model.infer_vector(word_tokenize(nlptext))\n",
        " vector = pd.DataFrame(vector).T\n",
        " vector.index = [ids]\n",
        " a.append(vector)\n",
        "textvectors = pd.concat(a)\n",
        "textvectors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "nxTsEQ8ewixr",
        "outputId": "456c1400-818d-444b-9707-0a34f4628b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6    \\\n",
              "0      0.221199  0.331877 -0.332932 -0.143180  0.114841  0.007604 -0.028700   \n",
              "1     -0.082753  0.201246  0.131660 -0.017309  0.080802 -0.241773  0.238145   \n",
              "2     -0.116307  0.433399  0.324086  0.318445 -0.145800 -0.127382  0.077291   \n",
              "3      0.078409 -0.170744 -0.082416 -0.011689  0.164153  0.079994 -0.085636   \n",
              "4     -0.131317  0.112325  0.203133  0.486649 -0.023085  0.232699 -0.020652   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "44828 -0.005884 -0.057826  0.057261 -0.045232  0.084563 -0.029124  0.025663   \n",
              "44829 -0.106896 -0.152507 -0.056599 -0.145463  0.152959  0.138858 -0.071907   \n",
              "44830 -0.077903 -0.237636 -0.242578  0.083256  0.086112  0.162927  0.188774   \n",
              "44831 -0.003358  0.014248 -0.004664  0.160442 -0.045702  0.046280  0.079180   \n",
              "44832  0.208821 -0.040229  0.148827 -0.185327  0.135575 -0.149389 -0.000108   \n",
              "\n",
              "            7         8         9    ...       340       341       342  \\\n",
              "0      0.172142  0.211286 -0.021508  ... -0.044028  0.399327 -0.062191   \n",
              "1      0.179774 -0.249412  0.107645  ...  0.253916 -0.060053 -0.002539   \n",
              "2     -0.133755  0.341922 -0.129767  ...  0.005878 -0.085363 -0.320783   \n",
              "3      0.140649 -0.152805 -0.034392  ...  0.215953  0.071021  0.108901   \n",
              "4      0.369451  0.048875  0.029301  ... -0.103153 -0.321159 -0.102373   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "44828  0.153593 -0.024561 -0.087083  ...  0.070761 -0.013762 -0.028703   \n",
              "44829  0.096140  0.060623 -0.016229  ... -0.085106 -0.153142  0.155456   \n",
              "44830  0.395371 -0.097747 -0.158647  ...  0.014706  0.000956 -0.039480   \n",
              "44831  0.257364 -0.049503 -0.121967  ...  0.098091 -0.123507 -0.082751   \n",
              "44832 -0.067035  0.056758  0.093301  ...  0.040366 -0.204810 -0.282792   \n",
              "\n",
              "            343       344       345       346       347       348       349  \n",
              "0      0.351848  0.214919  0.273866  0.014157  0.145514  0.047707 -0.306128  \n",
              "1     -0.040306 -0.034489 -0.090694  0.198258  0.019001 -0.300919 -0.363364  \n",
              "2     -0.267421  0.482514  0.304111  0.159666 -0.138879  0.048530  0.257447  \n",
              "3     -0.111622  0.123561 -0.029187  0.002183 -0.133840 -0.041305 -0.002318  \n",
              "4     -0.158022  0.186136  0.044516  0.082313 -0.274851  0.053601 -0.117965  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "44828 -0.144167  0.137005 -0.043255  0.073634  0.072506 -0.001655  0.024982  \n",
              "44829  0.063890  0.068109 -0.115918  0.195273 -0.009219  0.115154  0.085780  \n",
              "44830 -0.094244  0.067050  0.099072 -0.069785 -0.136884  0.081011 -0.087794  \n",
              "44831 -0.153656  0.142996 -0.088888 -0.099935 -0.178297 -0.057791  0.008529  \n",
              "44832 -0.104950  0.272722 -0.073349 -0.250217 -0.065728 -0.078406 -0.285242  \n",
              "\n",
              "[44600 rows x 350 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bcfced67-ef45-4f16-8657-73a203d8638b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>340</th>\n",
              "      <th>341</th>\n",
              "      <th>342</th>\n",
              "      <th>343</th>\n",
              "      <th>344</th>\n",
              "      <th>345</th>\n",
              "      <th>346</th>\n",
              "      <th>347</th>\n",
              "      <th>348</th>\n",
              "      <th>349</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.221199</td>\n",
              "      <td>0.331877</td>\n",
              "      <td>-0.332932</td>\n",
              "      <td>-0.143180</td>\n",
              "      <td>0.114841</td>\n",
              "      <td>0.007604</td>\n",
              "      <td>-0.028700</td>\n",
              "      <td>0.172142</td>\n",
              "      <td>0.211286</td>\n",
              "      <td>-0.021508</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.044028</td>\n",
              "      <td>0.399327</td>\n",
              "      <td>-0.062191</td>\n",
              "      <td>0.351848</td>\n",
              "      <td>0.214919</td>\n",
              "      <td>0.273866</td>\n",
              "      <td>0.014157</td>\n",
              "      <td>0.145514</td>\n",
              "      <td>0.047707</td>\n",
              "      <td>-0.306128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.082753</td>\n",
              "      <td>0.201246</td>\n",
              "      <td>0.131660</td>\n",
              "      <td>-0.017309</td>\n",
              "      <td>0.080802</td>\n",
              "      <td>-0.241773</td>\n",
              "      <td>0.238145</td>\n",
              "      <td>0.179774</td>\n",
              "      <td>-0.249412</td>\n",
              "      <td>0.107645</td>\n",
              "      <td>...</td>\n",
              "      <td>0.253916</td>\n",
              "      <td>-0.060053</td>\n",
              "      <td>-0.002539</td>\n",
              "      <td>-0.040306</td>\n",
              "      <td>-0.034489</td>\n",
              "      <td>-0.090694</td>\n",
              "      <td>0.198258</td>\n",
              "      <td>0.019001</td>\n",
              "      <td>-0.300919</td>\n",
              "      <td>-0.363364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.116307</td>\n",
              "      <td>0.433399</td>\n",
              "      <td>0.324086</td>\n",
              "      <td>0.318445</td>\n",
              "      <td>-0.145800</td>\n",
              "      <td>-0.127382</td>\n",
              "      <td>0.077291</td>\n",
              "      <td>-0.133755</td>\n",
              "      <td>0.341922</td>\n",
              "      <td>-0.129767</td>\n",
              "      <td>...</td>\n",
              "      <td>0.005878</td>\n",
              "      <td>-0.085363</td>\n",
              "      <td>-0.320783</td>\n",
              "      <td>-0.267421</td>\n",
              "      <td>0.482514</td>\n",
              "      <td>0.304111</td>\n",
              "      <td>0.159666</td>\n",
              "      <td>-0.138879</td>\n",
              "      <td>0.048530</td>\n",
              "      <td>0.257447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.078409</td>\n",
              "      <td>-0.170744</td>\n",
              "      <td>-0.082416</td>\n",
              "      <td>-0.011689</td>\n",
              "      <td>0.164153</td>\n",
              "      <td>0.079994</td>\n",
              "      <td>-0.085636</td>\n",
              "      <td>0.140649</td>\n",
              "      <td>-0.152805</td>\n",
              "      <td>-0.034392</td>\n",
              "      <td>...</td>\n",
              "      <td>0.215953</td>\n",
              "      <td>0.071021</td>\n",
              "      <td>0.108901</td>\n",
              "      <td>-0.111622</td>\n",
              "      <td>0.123561</td>\n",
              "      <td>-0.029187</td>\n",
              "      <td>0.002183</td>\n",
              "      <td>-0.133840</td>\n",
              "      <td>-0.041305</td>\n",
              "      <td>-0.002318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.131317</td>\n",
              "      <td>0.112325</td>\n",
              "      <td>0.203133</td>\n",
              "      <td>0.486649</td>\n",
              "      <td>-0.023085</td>\n",
              "      <td>0.232699</td>\n",
              "      <td>-0.020652</td>\n",
              "      <td>0.369451</td>\n",
              "      <td>0.048875</td>\n",
              "      <td>0.029301</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.103153</td>\n",
              "      <td>-0.321159</td>\n",
              "      <td>-0.102373</td>\n",
              "      <td>-0.158022</td>\n",
              "      <td>0.186136</td>\n",
              "      <td>0.044516</td>\n",
              "      <td>0.082313</td>\n",
              "      <td>-0.274851</td>\n",
              "      <td>0.053601</td>\n",
              "      <td>-0.117965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44828</th>\n",
              "      <td>-0.005884</td>\n",
              "      <td>-0.057826</td>\n",
              "      <td>0.057261</td>\n",
              "      <td>-0.045232</td>\n",
              "      <td>0.084563</td>\n",
              "      <td>-0.029124</td>\n",
              "      <td>0.025663</td>\n",
              "      <td>0.153593</td>\n",
              "      <td>-0.024561</td>\n",
              "      <td>-0.087083</td>\n",
              "      <td>...</td>\n",
              "      <td>0.070761</td>\n",
              "      <td>-0.013762</td>\n",
              "      <td>-0.028703</td>\n",
              "      <td>-0.144167</td>\n",
              "      <td>0.137005</td>\n",
              "      <td>-0.043255</td>\n",
              "      <td>0.073634</td>\n",
              "      <td>0.072506</td>\n",
              "      <td>-0.001655</td>\n",
              "      <td>0.024982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44829</th>\n",
              "      <td>-0.106896</td>\n",
              "      <td>-0.152507</td>\n",
              "      <td>-0.056599</td>\n",
              "      <td>-0.145463</td>\n",
              "      <td>0.152959</td>\n",
              "      <td>0.138858</td>\n",
              "      <td>-0.071907</td>\n",
              "      <td>0.096140</td>\n",
              "      <td>0.060623</td>\n",
              "      <td>-0.016229</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.085106</td>\n",
              "      <td>-0.153142</td>\n",
              "      <td>0.155456</td>\n",
              "      <td>0.063890</td>\n",
              "      <td>0.068109</td>\n",
              "      <td>-0.115918</td>\n",
              "      <td>0.195273</td>\n",
              "      <td>-0.009219</td>\n",
              "      <td>0.115154</td>\n",
              "      <td>0.085780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44830</th>\n",
              "      <td>-0.077903</td>\n",
              "      <td>-0.237636</td>\n",
              "      <td>-0.242578</td>\n",
              "      <td>0.083256</td>\n",
              "      <td>0.086112</td>\n",
              "      <td>0.162927</td>\n",
              "      <td>0.188774</td>\n",
              "      <td>0.395371</td>\n",
              "      <td>-0.097747</td>\n",
              "      <td>-0.158647</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014706</td>\n",
              "      <td>0.000956</td>\n",
              "      <td>-0.039480</td>\n",
              "      <td>-0.094244</td>\n",
              "      <td>0.067050</td>\n",
              "      <td>0.099072</td>\n",
              "      <td>-0.069785</td>\n",
              "      <td>-0.136884</td>\n",
              "      <td>0.081011</td>\n",
              "      <td>-0.087794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44831</th>\n",
              "      <td>-0.003358</td>\n",
              "      <td>0.014248</td>\n",
              "      <td>-0.004664</td>\n",
              "      <td>0.160442</td>\n",
              "      <td>-0.045702</td>\n",
              "      <td>0.046280</td>\n",
              "      <td>0.079180</td>\n",
              "      <td>0.257364</td>\n",
              "      <td>-0.049503</td>\n",
              "      <td>-0.121967</td>\n",
              "      <td>...</td>\n",
              "      <td>0.098091</td>\n",
              "      <td>-0.123507</td>\n",
              "      <td>-0.082751</td>\n",
              "      <td>-0.153656</td>\n",
              "      <td>0.142996</td>\n",
              "      <td>-0.088888</td>\n",
              "      <td>-0.099935</td>\n",
              "      <td>-0.178297</td>\n",
              "      <td>-0.057791</td>\n",
              "      <td>0.008529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44832</th>\n",
              "      <td>0.208821</td>\n",
              "      <td>-0.040229</td>\n",
              "      <td>0.148827</td>\n",
              "      <td>-0.185327</td>\n",
              "      <td>0.135575</td>\n",
              "      <td>-0.149389</td>\n",
              "      <td>-0.000108</td>\n",
              "      <td>-0.067035</td>\n",
              "      <td>0.056758</td>\n",
              "      <td>0.093301</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040366</td>\n",
              "      <td>-0.204810</td>\n",
              "      <td>-0.282792</td>\n",
              "      <td>-0.104950</td>\n",
              "      <td>0.272722</td>\n",
              "      <td>-0.073349</td>\n",
              "      <td>-0.250217</td>\n",
              "      <td>-0.065728</td>\n",
              "      <td>-0.078406</td>\n",
              "      <td>-0.285242</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>44600 rows × 350 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcfced67-ef45-4f16-8657-73a203d8638b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bcfced67-ef45-4f16-8657-73a203d8638b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bcfced67-ef45-4f16-8657-73a203d8638b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5055d28e-ffef-40f8-80d1-cace44470ed1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5055d28e-ffef-40f8-80d1-cace44470ed1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5055d28e-ffef-40f8-80d1-cace44470ed1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standarization"
      ],
      "metadata": {
        "id": "7kLhTzDGwypM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def properscaler(simio):\n",
        " scaler = StandardScaler()\n",
        " resultsWordstrans = scaler.fit_transform(simio)\n",
        " resultsWordstrans = pd.DataFrame(resultsWordstrans)\n",
        " resultsWordstrans.index = simio.index\n",
        " resultsWordstrans.columns = simio.columns\n",
        " return resultsWordstrans\n",
        "\n",
        "datasetR = properscaler(textvectors)"
      ],
      "metadata": {
        "id": "wzWgzxiiwzAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll split in train and test sets (on offensive language)"
      ],
      "metadata": {
        "id": "vzZckAVCycz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetR['target'] = maindataset['offensive_language'].values\n",
        "\n",
        "outp = train_test_split(datasetR, train_size=0.7)\n",
        "finaleval=outp[1]\n",
        "subset=outp[0]\n",
        "\n",
        "x_subset = subset.drop(columns=[\"target\"]).to_numpy()\n",
        "y_subset = subset['target'].to_numpy()\n",
        "x_finaleval = finaleval.drop(columns=[\"target\"]).to_numpy()\n",
        "y_finaleval = finaleval[['target']].to_numpy()\n",
        "#size of the training set\n",
        "len(y_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcpqXEW9y8YX",
        "outputId": "fc95a966-5186-4c8d-b3ba-7d2427725daa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31219"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The distribution of the response is relevant to select the activation functions used in the neural network"
      ],
      "metadata": {
        "id": "pwQWZi5mbuXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.displot(y_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "VEzgjxPdamjq",
        "outputId": "e7034aeb-0303-45be-c18e-5c8c7071505d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7c92803573d0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definitions for the neural network model using Tensorflow / keras. A sigmoid is selected as the final function since it is the selected outcome of a binary classification (the function tends to 0 or 1)."
      ],
      "metadata": {
        "id": "p9YoSY-90pWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize\n",
        "neur = tf.keras.models.Sequential()\n",
        "#layers\n",
        "neur.add(tf.keras.layers.Dense(units=100, activation='linear'))\n",
        "neur.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
        "neur.add(tf.keras.layers.Dense(units=500, activation='tanh'))\n",
        "\n",
        "#output layer\n",
        "neur.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "#using cross entropy as loss function, sigmoid for optimizer and recall and precision for binary classification\n",
        "neur.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n"
      ],
      "metadata": {
        "id": "mLmDJczM0XMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "yosQr3L--cOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neur.fit(x_subset, y_subset, batch_size=20000, epochs=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_I_Xh2jr-cx0",
        "outputId": "81210611-185c-41d9-af6b-13112f24ab05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.4528 - precision: 0.7990 - recall: 0.7790\n",
            "Epoch 2/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.4521 - precision: 0.7988 - recall: 0.7797\n",
            "Epoch 3/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.4514 - precision: 0.7990 - recall: 0.7803\n",
            "Epoch 4/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.4507 - precision: 0.7991 - recall: 0.7805\n",
            "Epoch 5/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.4500 - precision: 0.7993 - recall: 0.7805\n",
            "Epoch 6/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4493 - precision: 0.7996 - recall: 0.7815\n",
            "Epoch 7/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4487 - precision: 0.8000 - recall: 0.7820\n",
            "Epoch 8/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.4480 - precision: 0.7999 - recall: 0.7831\n",
            "Epoch 9/700\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.4473 - precision: 0.8004 - recall: 0.7839\n",
            "Epoch 10/700\n",
            "2/2 [==============================] - 1s 244ms/step - loss: 0.4466 - precision: 0.8009 - recall: 0.7832\n",
            "Epoch 11/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.4460 - precision: 0.8012 - recall: 0.7834\n",
            "Epoch 12/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.4453 - precision: 0.8016 - recall: 0.7838\n",
            "Epoch 13/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4446 - precision: 0.8018 - recall: 0.7841\n",
            "Epoch 14/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.4440 - precision: 0.8019 - recall: 0.7843\n",
            "Epoch 15/700\n",
            "2/2 [==============================] - 1s 267ms/step - loss: 0.4433 - precision: 0.8024 - recall: 0.7846\n",
            "Epoch 16/700\n",
            "2/2 [==============================] - 1s 388ms/step - loss: 0.4427 - precision: 0.8026 - recall: 0.7852\n",
            "Epoch 17/700\n",
            "2/2 [==============================] - 1s 413ms/step - loss: 0.4421 - precision: 0.8029 - recall: 0.7854\n",
            "Epoch 18/700\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 0.4414 - precision: 0.8032 - recall: 0.7859\n",
            "Epoch 19/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.4408 - precision: 0.8036 - recall: 0.7866\n",
            "Epoch 20/700\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.4401 - precision: 0.8040 - recall: 0.7870\n",
            "Epoch 21/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.4395 - precision: 0.8044 - recall: 0.7871\n",
            "Epoch 22/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.4389 - precision: 0.8051 - recall: 0.7865\n",
            "Epoch 23/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.4383 - precision: 0.8053 - recall: 0.7876\n",
            "Epoch 24/700\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.4376 - precision: 0.8063 - recall: 0.7875\n",
            "Epoch 25/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.4370 - precision: 0.8066 - recall: 0.7878\n",
            "Epoch 26/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.4364 - precision: 0.8065 - recall: 0.7887\n",
            "Epoch 27/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.4358 - precision: 0.8066 - recall: 0.7891\n",
            "Epoch 28/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.4352 - precision: 0.8072 - recall: 0.7892\n",
            "Epoch 29/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.4346 - precision: 0.8075 - recall: 0.7898\n",
            "Epoch 30/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.4340 - precision: 0.8079 - recall: 0.7899\n",
            "Epoch 31/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.4334 - precision: 0.8084 - recall: 0.7902\n",
            "Epoch 32/700\n",
            "2/2 [==============================] - 1s 375ms/step - loss: 0.4328 - precision: 0.8088 - recall: 0.7911\n",
            "Epoch 33/700\n",
            "2/2 [==============================] - 1s 426ms/step - loss: 0.4322 - precision: 0.8085 - recall: 0.7915\n",
            "Epoch 34/700\n",
            "2/2 [==============================] - 1s 420ms/step - loss: 0.4316 - precision: 0.8089 - recall: 0.7920\n",
            "Epoch 35/700\n",
            "2/2 [==============================] - 1s 432ms/step - loss: 0.4311 - precision: 0.8090 - recall: 0.7923\n",
            "Epoch 36/700\n",
            "2/2 [==============================] - 1s 404ms/step - loss: 0.4305 - precision: 0.8095 - recall: 0.7926\n",
            "Epoch 37/700\n",
            "2/2 [==============================] - 1s 386ms/step - loss: 0.4299 - precision: 0.8102 - recall: 0.7919\n",
            "Epoch 38/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.4293 - precision: 0.8102 - recall: 0.7937\n",
            "Epoch 39/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4288 - precision: 0.8106 - recall: 0.7936\n",
            "Epoch 40/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.4282 - precision: 0.8111 - recall: 0.7937\n",
            "Epoch 41/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.4276 - precision: 0.8115 - recall: 0.7941\n",
            "Epoch 42/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.4271 - precision: 0.8117 - recall: 0.7947\n",
            "Epoch 43/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.4265 - precision: 0.8117 - recall: 0.7957\n",
            "Epoch 44/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.4260 - precision: 0.8120 - recall: 0.7961\n",
            "Epoch 45/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.4254 - precision: 0.8123 - recall: 0.7959\n",
            "Epoch 46/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.4249 - precision: 0.8126 - recall: 0.7960\n",
            "Epoch 47/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.4243 - precision: 0.8135 - recall: 0.7959\n",
            "Epoch 48/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4238 - precision: 0.8135 - recall: 0.7967\n",
            "Epoch 49/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.4232 - precision: 0.8136 - recall: 0.7970\n",
            "Epoch 50/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.4227 - precision: 0.8136 - recall: 0.7974\n",
            "Epoch 51/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.4222 - precision: 0.8138 - recall: 0.7977\n",
            "Epoch 52/700\n",
            "2/2 [==============================] - 1s 267ms/step - loss: 0.4217 - precision: 0.8142 - recall: 0.7981\n",
            "Epoch 53/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.4211 - precision: 0.8148 - recall: 0.7980\n",
            "Epoch 54/700\n",
            "2/2 [==============================] - 1s 385ms/step - loss: 0.4206 - precision: 0.8148 - recall: 0.7983\n",
            "Epoch 55/700\n",
            "2/2 [==============================] - 1s 414ms/step - loss: 0.4201 - precision: 0.8152 - recall: 0.7991\n",
            "Epoch 56/700\n",
            "2/2 [==============================] - 1s 381ms/step - loss: 0.4196 - precision: 0.8153 - recall: 0.7995\n",
            "Epoch 57/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.4191 - precision: 0.8156 - recall: 0.7997\n",
            "Epoch 58/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.4186 - precision: 0.8159 - recall: 0.7998\n",
            "Epoch 59/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.4181 - precision: 0.8163 - recall: 0.8000\n",
            "Epoch 60/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.4176 - precision: 0.8161 - recall: 0.8004\n",
            "Epoch 61/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.4170 - precision: 0.8162 - recall: 0.8007\n",
            "Epoch 62/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.4165 - precision: 0.8170 - recall: 0.8004\n",
            "Epoch 63/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.4161 - precision: 0.8172 - recall: 0.8010\n",
            "Epoch 64/700\n",
            "2/2 [==============================] - 1s 650ms/step - loss: 0.4156 - precision: 0.8175 - recall: 0.8016\n",
            "Epoch 65/700\n",
            "2/2 [==============================] - 1s 257ms/step - loss: 0.4151 - precision: 0.8175 - recall: 0.8019\n",
            "Epoch 66/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.4146 - precision: 0.8181 - recall: 0.8019\n",
            "Epoch 67/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.4141 - precision: 0.8185 - recall: 0.8018\n",
            "Epoch 68/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.4136 - precision: 0.8188 - recall: 0.8014\n",
            "Epoch 69/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.4132 - precision: 0.8192 - recall: 0.8024\n",
            "Epoch 70/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.4127 - precision: 0.8196 - recall: 0.8023\n",
            "Epoch 71/700\n",
            "2/2 [==============================] - 1s 391ms/step - loss: 0.4122 - precision: 0.8200 - recall: 0.8030\n",
            "Epoch 72/700\n",
            "2/2 [==============================] - 1s 405ms/step - loss: 0.4118 - precision: 0.8200 - recall: 0.8031\n",
            "Epoch 73/700\n",
            "2/2 [==============================] - 1s 412ms/step - loss: 0.4113 - precision: 0.8201 - recall: 0.8034\n",
            "Epoch 74/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.4108 - precision: 0.8202 - recall: 0.8035\n",
            "Epoch 75/700\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.4104 - precision: 0.8206 - recall: 0.8035\n",
            "Epoch 76/700\n",
            "2/2 [==============================] - 1s 391ms/step - loss: 0.4099 - precision: 0.8207 - recall: 0.8040\n",
            "Epoch 77/700\n",
            "2/2 [==============================] - 2s 460ms/step - loss: 0.4095 - precision: 0.8205 - recall: 0.8041\n",
            "Epoch 78/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.4090 - precision: 0.8207 - recall: 0.8044\n",
            "Epoch 79/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.4086 - precision: 0.8211 - recall: 0.8046\n",
            "Epoch 80/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.4081 - precision: 0.8213 - recall: 0.8047\n",
            "Epoch 81/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.4077 - precision: 0.8212 - recall: 0.8048\n",
            "Epoch 82/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.4073 - precision: 0.8215 - recall: 0.8054\n",
            "Epoch 83/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.4068 - precision: 0.8218 - recall: 0.8054\n",
            "Epoch 84/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.4064 - precision: 0.8224 - recall: 0.8054\n",
            "Epoch 85/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.4060 - precision: 0.8227 - recall: 0.8054\n",
            "Epoch 86/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.4055 - precision: 0.8227 - recall: 0.8060\n",
            "Epoch 87/700\n",
            "2/2 [==============================] - 1s 252ms/step - loss: 0.4051 - precision: 0.8229 - recall: 0.8063\n",
            "Epoch 88/700\n",
            "2/2 [==============================] - 1s 387ms/step - loss: 0.4047 - precision: 0.8233 - recall: 0.8064\n",
            "Epoch 89/700\n",
            "2/2 [==============================] - 1s 404ms/step - loss: 0.4043 - precision: 0.8236 - recall: 0.8060\n",
            "Epoch 90/700\n",
            "2/2 [==============================] - 1s 416ms/step - loss: 0.4039 - precision: 0.8233 - recall: 0.8070\n",
            "Epoch 91/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.4035 - precision: 0.8236 - recall: 0.8067\n",
            "Epoch 92/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.4030 - precision: 0.8239 - recall: 0.8068\n",
            "Epoch 93/700\n",
            "2/2 [==============================] - 1s 250ms/step - loss: 0.4026 - precision: 0.8238 - recall: 0.8067\n",
            "Epoch 94/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.4022 - precision: 0.8243 - recall: 0.8069\n",
            "Epoch 95/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.4018 - precision: 0.8246 - recall: 0.8073\n",
            "Epoch 96/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.4014 - precision: 0.8249 - recall: 0.8073\n",
            "Epoch 97/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.4010 - precision: 0.8249 - recall: 0.8075\n",
            "Epoch 98/700\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.4006 - precision: 0.8247 - recall: 0.8079\n",
            "Epoch 99/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.4002 - precision: 0.8250 - recall: 0.8083\n",
            "Epoch 100/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3998 - precision: 0.8251 - recall: 0.8087\n",
            "Epoch 101/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3995 - precision: 0.8255 - recall: 0.8091\n",
            "Epoch 102/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3991 - precision: 0.8255 - recall: 0.8099\n",
            "Epoch 103/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3987 - precision: 0.8258 - recall: 0.8103\n",
            "Epoch 104/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3983 - precision: 0.8261 - recall: 0.8109\n",
            "Epoch 105/700\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.3979 - precision: 0.8264 - recall: 0.8108\n",
            "Epoch 106/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3976 - precision: 0.8267 - recall: 0.8111\n",
            "Epoch 107/700\n",
            "2/2 [==============================] - 1s 387ms/step - loss: 0.3972 - precision: 0.8266 - recall: 0.8114\n",
            "Epoch 108/700\n",
            "2/2 [==============================] - 1s 393ms/step - loss: 0.3968 - precision: 0.8268 - recall: 0.8113\n",
            "Epoch 109/700\n",
            "2/2 [==============================] - 1s 392ms/step - loss: 0.3965 - precision: 0.8271 - recall: 0.8117\n",
            "Epoch 110/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3961 - precision: 0.8275 - recall: 0.8116\n",
            "Epoch 111/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3957 - precision: 0.8276 - recall: 0.8123\n",
            "Epoch 112/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3954 - precision: 0.8276 - recall: 0.8126\n",
            "Epoch 113/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3950 - precision: 0.8284 - recall: 0.8123\n",
            "Epoch 114/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3946 - precision: 0.8284 - recall: 0.8126\n",
            "Epoch 115/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3943 - precision: 0.8286 - recall: 0.8125\n",
            "Epoch 116/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3939 - precision: 0.8286 - recall: 0.8125\n",
            "Epoch 117/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3936 - precision: 0.8290 - recall: 0.8125\n",
            "Epoch 118/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3932 - precision: 0.8290 - recall: 0.8131\n",
            "Epoch 119/700\n",
            "2/2 [==============================] - 1s 244ms/step - loss: 0.3929 - precision: 0.8294 - recall: 0.8130\n",
            "Epoch 120/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3925 - precision: 0.8294 - recall: 0.8134\n",
            "Epoch 121/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3922 - precision: 0.8296 - recall: 0.8130\n",
            "Epoch 122/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3919 - precision: 0.8299 - recall: 0.8130\n",
            "Epoch 123/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3915 - precision: 0.8302 - recall: 0.8130\n",
            "Epoch 124/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3912 - precision: 0.8302 - recall: 0.8132\n",
            "Epoch 125/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.3909 - precision: 0.8305 - recall: 0.8136\n",
            "Epoch 126/700\n",
            "2/2 [==============================] - 1s 353ms/step - loss: 0.3905 - precision: 0.8304 - recall: 0.8137\n",
            "Epoch 127/700\n",
            "2/2 [==============================] - 1s 375ms/step - loss: 0.3902 - precision: 0.8307 - recall: 0.8140\n",
            "Epoch 128/700\n",
            "2/2 [==============================] - 1s 360ms/step - loss: 0.3899 - precision: 0.8309 - recall: 0.8138\n",
            "Epoch 129/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3895 - precision: 0.8310 - recall: 0.8142\n",
            "Epoch 130/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3892 - precision: 0.8314 - recall: 0.8142\n",
            "Epoch 131/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3889 - precision: 0.8318 - recall: 0.8144\n",
            "Epoch 132/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3886 - precision: 0.8318 - recall: 0.8150\n",
            "Epoch 133/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3883 - precision: 0.8322 - recall: 0.8151\n",
            "Epoch 134/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3880 - precision: 0.8324 - recall: 0.8146\n",
            "Epoch 135/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3877 - precision: 0.8322 - recall: 0.8151\n",
            "Epoch 136/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3873 - precision: 0.8327 - recall: 0.8151\n",
            "Epoch 137/700\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.3870 - precision: 0.8332 - recall: 0.8151\n",
            "Epoch 138/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3867 - precision: 0.8328 - recall: 0.8155\n",
            "Epoch 139/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3864 - precision: 0.8333 - recall: 0.8145\n",
            "Epoch 140/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3861 - precision: 0.8334 - recall: 0.8150\n",
            "Epoch 141/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3858 - precision: 0.8335 - recall: 0.8151\n",
            "Epoch 142/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3855 - precision: 0.8337 - recall: 0.8152\n",
            "Epoch 143/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3852 - precision: 0.8337 - recall: 0.8153\n",
            "Epoch 144/700\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.3849 - precision: 0.8339 - recall: 0.8153\n",
            "Epoch 145/700\n",
            "2/2 [==============================] - 1s 335ms/step - loss: 0.3846 - precision: 0.8343 - recall: 0.8151\n",
            "Epoch 146/700\n",
            "2/2 [==============================] - 1s 421ms/step - loss: 0.3844 - precision: 0.8343 - recall: 0.8155\n",
            "Epoch 147/700\n",
            "2/2 [==============================] - 1s 402ms/step - loss: 0.3841 - precision: 0.8339 - recall: 0.8159\n",
            "Epoch 148/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3838 - precision: 0.8341 - recall: 0.8158\n",
            "Epoch 149/700\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.3835 - precision: 0.8342 - recall: 0.8164\n",
            "Epoch 150/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3832 - precision: 0.8349 - recall: 0.8158\n",
            "Epoch 151/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3829 - precision: 0.8350 - recall: 0.8158\n",
            "Epoch 152/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3826 - precision: 0.8352 - recall: 0.8160\n",
            "Epoch 153/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3824 - precision: 0.8355 - recall: 0.8161\n",
            "Epoch 154/700\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.3821 - precision: 0.8360 - recall: 0.8159\n",
            "Epoch 155/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3818 - precision: 0.8365 - recall: 0.8159\n",
            "Epoch 156/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3815 - precision: 0.8366 - recall: 0.8167\n",
            "Epoch 157/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3813 - precision: 0.8367 - recall: 0.8167\n",
            "Epoch 158/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3810 - precision: 0.8367 - recall: 0.8171\n",
            "Epoch 159/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3807 - precision: 0.8368 - recall: 0.8170\n",
            "Epoch 160/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3805 - precision: 0.8365 - recall: 0.8173\n",
            "Epoch 161/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3802 - precision: 0.8368 - recall: 0.8174\n",
            "Epoch 162/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3799 - precision: 0.8374 - recall: 0.8171\n",
            "Epoch 163/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3797 - precision: 0.8372 - recall: 0.8172\n",
            "Epoch 164/700\n",
            "2/2 [==============================] - 1s 294ms/step - loss: 0.3794 - precision: 0.8373 - recall: 0.8176\n",
            "Epoch 165/700\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.3792 - precision: 0.8373 - recall: 0.8173\n",
            "Epoch 166/700\n",
            "2/2 [==============================] - 1s 399ms/step - loss: 0.3789 - precision: 0.8374 - recall: 0.8174\n",
            "Epoch 167/700\n",
            "2/2 [==============================] - 1s 280ms/step - loss: 0.3786 - precision: 0.8378 - recall: 0.8174\n",
            "Epoch 168/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3784 - precision: 0.8380 - recall: 0.8180\n",
            "Epoch 169/700\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.3781 - precision: 0.8383 - recall: 0.8178\n",
            "Epoch 170/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3779 - precision: 0.8385 - recall: 0.8177\n",
            "Epoch 171/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3776 - precision: 0.8385 - recall: 0.8178\n",
            "Epoch 172/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3774 - precision: 0.8388 - recall: 0.8178\n",
            "Epoch 173/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3771 - precision: 0.8389 - recall: 0.8180\n",
            "Epoch 174/700\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3769 - precision: 0.8393 - recall: 0.8181\n",
            "Epoch 175/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3766 - precision: 0.8395 - recall: 0.8182\n",
            "Epoch 176/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3764 - precision: 0.8400 - recall: 0.8180\n",
            "Epoch 177/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3762 - precision: 0.8397 - recall: 0.8184\n",
            "Epoch 178/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3759 - precision: 0.8403 - recall: 0.8184\n",
            "Epoch 179/700\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.3757 - precision: 0.8402 - recall: 0.8188\n",
            "Epoch 180/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3754 - precision: 0.8399 - recall: 0.8192\n",
            "Epoch 181/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3752 - precision: 0.8404 - recall: 0.8190\n",
            "Epoch 182/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3750 - precision: 0.8404 - recall: 0.8190\n",
            "Epoch 183/700\n",
            "2/2 [==============================] - 1s 262ms/step - loss: 0.3747 - precision: 0.8406 - recall: 0.8191\n",
            "Epoch 184/700\n",
            "2/2 [==============================] - 1s 403ms/step - loss: 0.3745 - precision: 0.8407 - recall: 0.8190\n",
            "Epoch 185/700\n",
            "2/2 [==============================] - 1s 434ms/step - loss: 0.3743 - precision: 0.8409 - recall: 0.8188\n",
            "Epoch 186/700\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.3741 - precision: 0.8405 - recall: 0.8193\n",
            "Epoch 187/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3738 - precision: 0.8411 - recall: 0.8190\n",
            "Epoch 188/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3736 - precision: 0.8410 - recall: 0.8194\n",
            "Epoch 189/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3734 - precision: 0.8414 - recall: 0.8194\n",
            "Epoch 190/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3731 - precision: 0.8412 - recall: 0.8197\n",
            "Epoch 191/700\n",
            "2/2 [==============================] - 1s 244ms/step - loss: 0.3729 - precision: 0.8413 - recall: 0.8200\n",
            "Epoch 192/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3727 - precision: 0.8414 - recall: 0.8201\n",
            "Epoch 193/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3725 - precision: 0.8414 - recall: 0.8202\n",
            "Epoch 194/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3723 - precision: 0.8416 - recall: 0.8201\n",
            "Epoch 195/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3720 - precision: 0.8416 - recall: 0.8201\n",
            "Epoch 196/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3718 - precision: 0.8415 - recall: 0.8207\n",
            "Epoch 197/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3716 - precision: 0.8419 - recall: 0.8204\n",
            "Epoch 198/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3714 - precision: 0.8419 - recall: 0.8203\n",
            "Epoch 199/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3712 - precision: 0.8422 - recall: 0.8203\n",
            "Epoch 200/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3710 - precision: 0.8422 - recall: 0.8204\n",
            "Epoch 201/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3708 - precision: 0.8422 - recall: 0.8205\n",
            "Epoch 202/700\n",
            "2/2 [==============================] - 1s 248ms/step - loss: 0.3706 - precision: 0.8423 - recall: 0.8206\n",
            "Epoch 203/700\n",
            "2/2 [==============================] - 1s 400ms/step - loss: 0.3703 - precision: 0.8423 - recall: 0.8209\n",
            "Epoch 204/700\n",
            "2/2 [==============================] - 1s 415ms/step - loss: 0.3701 - precision: 0.8423 - recall: 0.8213\n",
            "Epoch 205/700\n",
            "2/2 [==============================] - 1s 263ms/step - loss: 0.3699 - precision: 0.8424 - recall: 0.8218\n",
            "Epoch 206/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3697 - precision: 0.8426 - recall: 0.8218\n",
            "Epoch 207/700\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.3695 - precision: 0.8433 - recall: 0.8214\n",
            "Epoch 208/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3693 - precision: 0.8433 - recall: 0.8218\n",
            "Epoch 209/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3691 - precision: 0.8434 - recall: 0.8217\n",
            "Epoch 210/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3689 - precision: 0.8437 - recall: 0.8222\n",
            "Epoch 211/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3687 - precision: 0.8437 - recall: 0.8224\n",
            "Epoch 212/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3685 - precision: 0.8441 - recall: 0.8224\n",
            "Epoch 213/700\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3683 - precision: 0.8442 - recall: 0.8230\n",
            "Epoch 214/700\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.3681 - precision: 0.8443 - recall: 0.8230\n",
            "Epoch 215/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3679 - precision: 0.8447 - recall: 0.8228\n",
            "Epoch 216/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3677 - precision: 0.8449 - recall: 0.8230\n",
            "Epoch 217/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3675 - precision: 0.8450 - recall: 0.8228\n",
            "Epoch 218/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3673 - precision: 0.8450 - recall: 0.8232\n",
            "Epoch 219/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3672 - precision: 0.8450 - recall: 0.8236\n",
            "Epoch 220/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3670 - precision: 0.8453 - recall: 0.8239\n",
            "Epoch 221/700\n",
            "2/2 [==============================] - 1s 261ms/step - loss: 0.3668 - precision: 0.8450 - recall: 0.8245\n",
            "Epoch 222/700\n",
            "2/2 [==============================] - 1s 403ms/step - loss: 0.3666 - precision: 0.8456 - recall: 0.8243\n",
            "Epoch 223/700\n",
            "2/2 [==============================] - 1s 400ms/step - loss: 0.3664 - precision: 0.8452 - recall: 0.8247\n",
            "Epoch 224/700\n",
            "2/2 [==============================] - 1s 338ms/step - loss: 0.3662 - precision: 0.8455 - recall: 0.8247\n",
            "Epoch 225/700\n",
            "2/2 [==============================] - 1s 244ms/step - loss: 0.3660 - precision: 0.8460 - recall: 0.8245\n",
            "Epoch 226/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3658 - precision: 0.8458 - recall: 0.8243\n",
            "Epoch 227/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3656 - precision: 0.8458 - recall: 0.8245\n",
            "Epoch 228/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3655 - precision: 0.8459 - recall: 0.8246\n",
            "Epoch 229/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3653 - precision: 0.8460 - recall: 0.8245\n",
            "Epoch 230/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3651 - precision: 0.8460 - recall: 0.8251\n",
            "Epoch 231/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3649 - precision: 0.8463 - recall: 0.8245\n",
            "Epoch 232/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3647 - precision: 0.8464 - recall: 0.8246\n",
            "Epoch 233/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3646 - precision: 0.8464 - recall: 0.8250\n",
            "Epoch 234/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3644 - precision: 0.8465 - recall: 0.8249\n",
            "Epoch 235/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3642 - precision: 0.8465 - recall: 0.8249\n",
            "Epoch 236/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3640 - precision: 0.8464 - recall: 0.8248\n",
            "Epoch 237/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3638 - precision: 0.8464 - recall: 0.8248\n",
            "Epoch 238/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3637 - precision: 0.8468 - recall: 0.8248\n",
            "Epoch 239/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3635 - precision: 0.8467 - recall: 0.8253\n",
            "Epoch 240/700\n",
            "2/2 [==============================] - 1s 332ms/step - loss: 0.3633 - precision: 0.8472 - recall: 0.8250\n",
            "Epoch 241/700\n",
            "2/2 [==============================] - 1s 421ms/step - loss: 0.3632 - precision: 0.8471 - recall: 0.8251\n",
            "Epoch 242/700\n",
            "2/2 [==============================] - 1s 418ms/step - loss: 0.3630 - precision: 0.8472 - recall: 0.8257\n",
            "Epoch 243/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.3628 - precision: 0.8474 - recall: 0.8255\n",
            "Epoch 244/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3626 - precision: 0.8473 - recall: 0.8258\n",
            "Epoch 245/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3625 - precision: 0.8475 - recall: 0.8259\n",
            "Epoch 246/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3623 - precision: 0.8475 - recall: 0.8261\n",
            "Epoch 247/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3621 - precision: 0.8474 - recall: 0.8261\n",
            "Epoch 248/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3620 - precision: 0.8476 - recall: 0.8264\n",
            "Epoch 249/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3618 - precision: 0.8477 - recall: 0.8262\n",
            "Epoch 250/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3616 - precision: 0.8478 - recall: 0.8262\n",
            "Epoch 251/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3615 - precision: 0.8481 - recall: 0.8259\n",
            "Epoch 252/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3613 - precision: 0.8481 - recall: 0.8264\n",
            "Epoch 253/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3611 - precision: 0.8486 - recall: 0.8262\n",
            "Epoch 254/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3610 - precision: 0.8486 - recall: 0.8264\n",
            "Epoch 255/700\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.3608 - precision: 0.8486 - recall: 0.8265\n",
            "Epoch 256/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3606 - precision: 0.8488 - recall: 0.8264\n",
            "Epoch 257/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3605 - precision: 0.8488 - recall: 0.8265\n",
            "Epoch 258/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3603 - precision: 0.8487 - recall: 0.8268\n",
            "Epoch 259/700\n",
            "2/2 [==============================] - 1s 358ms/step - loss: 0.3602 - precision: 0.8489 - recall: 0.8267\n",
            "Epoch 260/700\n",
            "2/2 [==============================] - 1s 396ms/step - loss: 0.3600 - precision: 0.8492 - recall: 0.8268\n",
            "Epoch 261/700\n",
            "2/2 [==============================] - 1s 402ms/step - loss: 0.3598 - precision: 0.8489 - recall: 0.8275\n",
            "Epoch 262/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3597 - precision: 0.8492 - recall: 0.8276\n",
            "Epoch 263/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3595 - precision: 0.8494 - recall: 0.8276\n",
            "Epoch 264/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3594 - precision: 0.8497 - recall: 0.8275\n",
            "Epoch 265/700\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.3592 - precision: 0.8498 - recall: 0.8276\n",
            "Epoch 266/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3591 - precision: 0.8500 - recall: 0.8277\n",
            "Epoch 267/700\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.3589 - precision: 0.8498 - recall: 0.8278\n",
            "Epoch 268/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3588 - precision: 0.8499 - recall: 0.8278\n",
            "Epoch 269/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3586 - precision: 0.8500 - recall: 0.8280\n",
            "Epoch 270/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3585 - precision: 0.8501 - recall: 0.8280\n",
            "Epoch 271/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3583 - precision: 0.8505 - recall: 0.8275\n",
            "Epoch 272/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3582 - precision: 0.8503 - recall: 0.8278\n",
            "Epoch 273/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3580 - precision: 0.8507 - recall: 0.8278\n",
            "Epoch 274/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3579 - precision: 0.8508 - recall: 0.8280\n",
            "Epoch 275/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3577 - precision: 0.8510 - recall: 0.8276\n",
            "Epoch 276/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3576 - precision: 0.8510 - recall: 0.8280\n",
            "Epoch 277/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3574 - precision: 0.8511 - recall: 0.8279\n",
            "Epoch 278/700\n",
            "2/2 [==============================] - 1s 370ms/step - loss: 0.3573 - precision: 0.8513 - recall: 0.8278\n",
            "Epoch 279/700\n",
            "2/2 [==============================] - 1s 412ms/step - loss: 0.3571 - precision: 0.8512 - recall: 0.8280\n",
            "Epoch 280/700\n",
            "2/2 [==============================] - 1s 385ms/step - loss: 0.3570 - precision: 0.8512 - recall: 0.8280\n",
            "Epoch 281/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3568 - precision: 0.8513 - recall: 0.8280\n",
            "Epoch 282/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3567 - precision: 0.8512 - recall: 0.8285\n",
            "Epoch 283/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3565 - precision: 0.8513 - recall: 0.8284\n",
            "Epoch 284/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3564 - precision: 0.8513 - recall: 0.8282\n",
            "Epoch 285/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3562 - precision: 0.8516 - recall: 0.8285\n",
            "Epoch 286/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3561 - precision: 0.8517 - recall: 0.8288\n",
            "Epoch 287/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3560 - precision: 0.8517 - recall: 0.8287\n",
            "Epoch 288/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3558 - precision: 0.8520 - recall: 0.8285\n",
            "Epoch 289/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3557 - precision: 0.8521 - recall: 0.8288\n",
            "Epoch 290/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3555 - precision: 0.8523 - recall: 0.8287\n",
            "Epoch 291/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3554 - precision: 0.8525 - recall: 0.8288\n",
            "Epoch 292/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3553 - precision: 0.8527 - recall: 0.8289\n",
            "Epoch 293/700\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.3551 - precision: 0.8528 - recall: 0.8286\n",
            "Epoch 294/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3550 - precision: 0.8528 - recall: 0.8291\n",
            "Epoch 295/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3548 - precision: 0.8528 - recall: 0.8294\n",
            "Epoch 296/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3547 - precision: 0.8528 - recall: 0.8295\n",
            "Epoch 297/700\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 0.3546 - precision: 0.8528 - recall: 0.8295\n",
            "Epoch 298/700\n",
            "2/2 [==============================] - 1s 380ms/step - loss: 0.3544 - precision: 0.8529 - recall: 0.8295\n",
            "Epoch 299/700\n",
            "2/2 [==============================] - 1s 410ms/step - loss: 0.3543 - precision: 0.8529 - recall: 0.8294\n",
            "Epoch 300/700\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.3542 - precision: 0.8530 - recall: 0.8294\n",
            "Epoch 301/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3540 - precision: 0.8534 - recall: 0.8294\n",
            "Epoch 302/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3539 - precision: 0.8534 - recall: 0.8295\n",
            "Epoch 303/700\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.3538 - precision: 0.8534 - recall: 0.8298\n",
            "Epoch 304/700\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.3536 - precision: 0.8538 - recall: 0.8297\n",
            "Epoch 305/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3535 - precision: 0.8536 - recall: 0.8295\n",
            "Epoch 306/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3534 - precision: 0.8538 - recall: 0.8297\n",
            "Epoch 307/700\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.3532 - precision: 0.8537 - recall: 0.8298\n",
            "Epoch 308/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3531 - precision: 0.8539 - recall: 0.8294\n",
            "Epoch 309/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3530 - precision: 0.8537 - recall: 0.8295\n",
            "Epoch 310/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3528 - precision: 0.8538 - recall: 0.8296\n",
            "Epoch 311/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3527 - precision: 0.8536 - recall: 0.8301\n",
            "Epoch 312/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3526 - precision: 0.8535 - recall: 0.8304\n",
            "Epoch 313/700\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.3524 - precision: 0.8536 - recall: 0.8304\n",
            "Epoch 314/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3523 - precision: 0.8537 - recall: 0.8302\n",
            "Epoch 315/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3522 - precision: 0.8537 - recall: 0.8306\n",
            "Epoch 316/700\n",
            "2/2 [==============================] - 1s 354ms/step - loss: 0.3520 - precision: 0.8541 - recall: 0.8302\n",
            "Epoch 317/700\n",
            "2/2 [==============================] - 1s 390ms/step - loss: 0.3519 - precision: 0.8542 - recall: 0.8303\n",
            "Epoch 318/700\n",
            "2/2 [==============================] - 1s 394ms/step - loss: 0.3518 - precision: 0.8541 - recall: 0.8303\n",
            "Epoch 319/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3517 - precision: 0.8541 - recall: 0.8304\n",
            "Epoch 320/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3515 - precision: 0.8541 - recall: 0.8305\n",
            "Epoch 321/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3514 - precision: 0.8540 - recall: 0.8308\n",
            "Epoch 322/700\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.3513 - precision: 0.8541 - recall: 0.8307\n",
            "Epoch 323/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3512 - precision: 0.8541 - recall: 0.8308\n",
            "Epoch 324/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3510 - precision: 0.8541 - recall: 0.8306\n",
            "Epoch 325/700\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.3509 - precision: 0.8542 - recall: 0.8306\n",
            "Epoch 326/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3508 - precision: 0.8544 - recall: 0.8304\n",
            "Epoch 327/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3507 - precision: 0.8545 - recall: 0.8305\n",
            "Epoch 328/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3505 - precision: 0.8543 - recall: 0.8306\n",
            "Epoch 329/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3504 - precision: 0.8541 - recall: 0.8312\n",
            "Epoch 330/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3503 - precision: 0.8543 - recall: 0.8308\n",
            "Epoch 331/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3502 - precision: 0.8544 - recall: 0.8310\n",
            "Epoch 332/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3500 - precision: 0.8544 - recall: 0.8312\n",
            "Epoch 333/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3499 - precision: 0.8546 - recall: 0.8304\n",
            "Epoch 334/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3498 - precision: 0.8545 - recall: 0.8311\n",
            "Epoch 335/700\n",
            "2/2 [==============================] - 1s 401ms/step - loss: 0.3497 - precision: 0.8546 - recall: 0.8311\n",
            "Epoch 336/700\n",
            "2/2 [==============================] - 1s 376ms/step - loss: 0.3496 - precision: 0.8547 - recall: 0.8310\n",
            "Epoch 337/700\n",
            "2/2 [==============================] - 1s 394ms/step - loss: 0.3494 - precision: 0.8547 - recall: 0.8312\n",
            "Epoch 338/700\n",
            "2/2 [==============================] - 1s 264ms/step - loss: 0.3493 - precision: 0.8550 - recall: 0.8310\n",
            "Epoch 339/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3492 - precision: 0.8552 - recall: 0.8307\n",
            "Epoch 340/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3491 - precision: 0.8553 - recall: 0.8310\n",
            "Epoch 341/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3490 - precision: 0.8552 - recall: 0.8312\n",
            "Epoch 342/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3488 - precision: 0.8554 - recall: 0.8313\n",
            "Epoch 343/700\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.3487 - precision: 0.8555 - recall: 0.8312\n",
            "Epoch 344/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3486 - precision: 0.8556 - recall: 0.8314\n",
            "Epoch 345/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3485 - precision: 0.8555 - recall: 0.8314\n",
            "Epoch 346/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3484 - precision: 0.8556 - recall: 0.8316\n",
            "Epoch 347/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3482 - precision: 0.8555 - recall: 0.8318\n",
            "Epoch 348/700\n",
            "2/2 [==============================] - 1s 260ms/step - loss: 0.3481 - precision: 0.8558 - recall: 0.8318\n",
            "Epoch 349/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.3480 - precision: 0.8557 - recall: 0.8323\n",
            "Epoch 350/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3479 - precision: 0.8556 - recall: 0.8323\n",
            "Epoch 351/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3478 - precision: 0.8559 - recall: 0.8322\n",
            "Epoch 352/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3477 - precision: 0.8557 - recall: 0.8322\n",
            "Epoch 353/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3476 - precision: 0.8557 - recall: 0.8324\n",
            "Epoch 354/700\n",
            "2/2 [==============================] - 1s 394ms/step - loss: 0.3474 - precision: 0.8558 - recall: 0.8323\n",
            "Epoch 355/700\n",
            "2/2 [==============================] - 1s 372ms/step - loss: 0.3473 - precision: 0.8560 - recall: 0.8324\n",
            "Epoch 356/700\n",
            "2/2 [==============================] - 1s 359ms/step - loss: 0.3472 - precision: 0.8557 - recall: 0.8324\n",
            "Epoch 357/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3471 - precision: 0.8559 - recall: 0.8327\n",
            "Epoch 358/700\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.3470 - precision: 0.8555 - recall: 0.8328\n",
            "Epoch 359/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3469 - precision: 0.8558 - recall: 0.8324\n",
            "Epoch 360/700\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.3468 - precision: 0.8564 - recall: 0.8326\n",
            "Epoch 361/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3466 - precision: 0.8565 - recall: 0.8326\n",
            "Epoch 362/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3465 - precision: 0.8561 - recall: 0.8328\n",
            "Epoch 363/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3464 - precision: 0.8563 - recall: 0.8328\n",
            "Epoch 364/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3463 - precision: 0.8566 - recall: 0.8327\n",
            "Epoch 365/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3462 - precision: 0.8566 - recall: 0.8328\n",
            "Epoch 366/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3461 - precision: 0.8568 - recall: 0.8328\n",
            "Epoch 367/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3460 - precision: 0.8569 - recall: 0.8326\n",
            "Epoch 368/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3459 - precision: 0.8572 - recall: 0.8326\n",
            "Epoch 369/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3457 - precision: 0.8572 - recall: 0.8326\n",
            "Epoch 370/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3456 - precision: 0.8572 - recall: 0.8326\n",
            "Epoch 371/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3455 - precision: 0.8572 - recall: 0.8326\n",
            "Epoch 372/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3454 - precision: 0.8575 - recall: 0.8324\n",
            "Epoch 373/700\n",
            "2/2 [==============================] - 1s 428ms/step - loss: 0.3453 - precision: 0.8573 - recall: 0.8328\n",
            "Epoch 374/700\n",
            "2/2 [==============================] - 1s 378ms/step - loss: 0.3452 - precision: 0.8576 - recall: 0.8324\n",
            "Epoch 375/700\n",
            "2/2 [==============================] - 1s 396ms/step - loss: 0.3451 - precision: 0.8576 - recall: 0.8323\n",
            "Epoch 376/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3450 - precision: 0.8576 - recall: 0.8326\n",
            "Epoch 377/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3449 - precision: 0.8578 - recall: 0.8322\n",
            "Epoch 378/700\n",
            "2/2 [==============================] - 1s 208ms/step - loss: 0.3448 - precision: 0.8578 - recall: 0.8326\n",
            "Epoch 379/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3447 - precision: 0.8575 - recall: 0.8330\n",
            "Epoch 380/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3445 - precision: 0.8579 - recall: 0.8327\n",
            "Epoch 381/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3444 - precision: 0.8577 - recall: 0.8331\n",
            "Epoch 382/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3443 - precision: 0.8578 - recall: 0.8330\n",
            "Epoch 383/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3442 - precision: 0.8580 - recall: 0.8328\n",
            "Epoch 384/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3441 - precision: 0.8581 - recall: 0.8331\n",
            "Epoch 385/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3440 - precision: 0.8582 - recall: 0.8333\n",
            "Epoch 386/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3439 - precision: 0.8585 - recall: 0.8332\n",
            "Epoch 387/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3438 - precision: 0.8582 - recall: 0.8333\n",
            "Epoch 388/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3437 - precision: 0.8583 - recall: 0.8334\n",
            "Epoch 389/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3436 - precision: 0.8585 - recall: 0.8334\n",
            "Epoch 390/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3435 - precision: 0.8587 - recall: 0.8331\n",
            "Epoch 391/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3434 - precision: 0.8589 - recall: 0.8331\n",
            "Epoch 392/700\n",
            "2/2 [==============================] - 1s 399ms/step - loss: 0.3433 - precision: 0.8589 - recall: 0.8333\n",
            "Epoch 393/700\n",
            "2/2 [==============================] - 1s 384ms/step - loss: 0.3432 - precision: 0.8588 - recall: 0.8336\n",
            "Epoch 394/700\n",
            "2/2 [==============================] - 1s 395ms/step - loss: 0.3431 - precision: 0.8589 - recall: 0.8337\n",
            "Epoch 395/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3429 - precision: 0.8589 - recall: 0.8337\n",
            "Epoch 396/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.3428 - precision: 0.8590 - recall: 0.8335\n",
            "Epoch 397/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3427 - precision: 0.8590 - recall: 0.8338\n",
            "Epoch 398/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3426 - precision: 0.8591 - recall: 0.8341\n",
            "Epoch 399/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3425 - precision: 0.8591 - recall: 0.8345\n",
            "Epoch 400/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3424 - precision: 0.8590 - recall: 0.8345\n",
            "Epoch 401/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3423 - precision: 0.8592 - recall: 0.8343\n",
            "Epoch 402/700\n",
            "2/2 [==============================] - 1s 395ms/step - loss: 0.3422 - precision: 0.8592 - recall: 0.8341\n",
            "Epoch 403/700\n",
            "2/2 [==============================] - 1s 379ms/step - loss: 0.3421 - precision: 0.8590 - recall: 0.8345\n",
            "Epoch 404/700\n",
            "2/2 [==============================] - 1s 395ms/step - loss: 0.3420 - precision: 0.8594 - recall: 0.8342\n",
            "Epoch 405/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3419 - precision: 0.8594 - recall: 0.8341\n",
            "Epoch 406/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3418 - precision: 0.8595 - recall: 0.8343\n",
            "Epoch 407/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3417 - precision: 0.8599 - recall: 0.8340\n",
            "Epoch 408/700\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.3416 - precision: 0.8597 - recall: 0.8344\n",
            "Epoch 409/700\n",
            "2/2 [==============================] - 1s 414ms/step - loss: 0.3415 - precision: 0.8598 - recall: 0.8342\n",
            "Epoch 410/700\n",
            "2/2 [==============================] - 1s 406ms/step - loss: 0.3414 - precision: 0.8598 - recall: 0.8345\n",
            "Epoch 411/700\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.3413 - precision: 0.8597 - recall: 0.8347\n",
            "Epoch 412/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3412 - precision: 0.8598 - recall: 0.8347\n",
            "Epoch 413/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3411 - precision: 0.8598 - recall: 0.8346\n",
            "Epoch 414/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3410 - precision: 0.8599 - recall: 0.8349\n",
            "Epoch 415/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3409 - precision: 0.8598 - recall: 0.8348\n",
            "Epoch 416/700\n",
            "2/2 [==============================] - 1s 207ms/step - loss: 0.3408 - precision: 0.8600 - recall: 0.8349\n",
            "Epoch 417/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3407 - precision: 0.8599 - recall: 0.8348\n",
            "Epoch 418/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3406 - precision: 0.8597 - recall: 0.8354\n",
            "Epoch 419/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3405 - precision: 0.8598 - recall: 0.8353\n",
            "Epoch 420/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3404 - precision: 0.8598 - recall: 0.8351\n",
            "Epoch 421/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3403 - precision: 0.8599 - recall: 0.8354\n",
            "Epoch 422/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3402 - precision: 0.8600 - recall: 0.8355\n",
            "Epoch 423/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3401 - precision: 0.8598 - recall: 0.8357\n",
            "Epoch 424/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3400 - precision: 0.8601 - recall: 0.8356\n",
            "Epoch 425/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3399 - precision: 0.8600 - recall: 0.8355\n",
            "Epoch 426/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3398 - precision: 0.8600 - recall: 0.8359\n",
            "Epoch 427/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.3397 - precision: 0.8603 - recall: 0.8354\n",
            "Epoch 428/700\n",
            "2/2 [==============================] - 1s 419ms/step - loss: 0.3396 - precision: 0.8605 - recall: 0.8355\n",
            "Epoch 429/700\n",
            "2/2 [==============================] - 1s 402ms/step - loss: 0.3395 - precision: 0.8605 - recall: 0.8355\n",
            "Epoch 430/700\n",
            "2/2 [==============================] - 1s 344ms/step - loss: 0.3394 - precision: 0.8605 - recall: 0.8357\n",
            "Epoch 431/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3393 - precision: 0.8605 - recall: 0.8356\n",
            "Epoch 432/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3392 - precision: 0.8608 - recall: 0.8354\n",
            "Epoch 433/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3391 - precision: 0.8606 - recall: 0.8359\n",
            "Epoch 434/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3390 - precision: 0.8606 - recall: 0.8360\n",
            "Epoch 435/700\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.3389 - precision: 0.8607 - recall: 0.8360\n",
            "Epoch 436/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3388 - precision: 0.8606 - recall: 0.8362\n",
            "Epoch 437/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3387 - precision: 0.8608 - recall: 0.8360\n",
            "Epoch 438/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3387 - precision: 0.8606 - recall: 0.8362\n",
            "Epoch 439/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3386 - precision: 0.8610 - recall: 0.8362\n",
            "Epoch 440/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3385 - precision: 0.8608 - recall: 0.8362\n",
            "Epoch 441/700\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3384 - precision: 0.8607 - recall: 0.8362\n",
            "Epoch 442/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3383 - precision: 0.8609 - recall: 0.8360\n",
            "Epoch 443/700\n",
            "2/2 [==============================] - 1s 213ms/step - loss: 0.3382 - precision: 0.8614 - recall: 0.8358\n",
            "Epoch 444/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3381 - precision: 0.8612 - recall: 0.8359\n",
            "Epoch 445/700\n",
            "2/2 [==============================] - 1s 247ms/step - loss: 0.3380 - precision: 0.8613 - recall: 0.8357\n",
            "Epoch 446/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3379 - precision: 0.8614 - recall: 0.8358\n",
            "Epoch 447/700\n",
            "2/2 [==============================] - 1s 388ms/step - loss: 0.3378 - precision: 0.8614 - recall: 0.8359\n",
            "Epoch 448/700\n",
            "2/2 [==============================] - 1s 341ms/step - loss: 0.3377 - precision: 0.8617 - recall: 0.8359\n",
            "Epoch 449/700\n",
            "2/2 [==============================] - 1s 389ms/step - loss: 0.3376 - precision: 0.8618 - recall: 0.8357\n",
            "Epoch 450/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3375 - precision: 0.8616 - recall: 0.8360\n",
            "Epoch 451/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3374 - precision: 0.8618 - recall: 0.8359\n",
            "Epoch 452/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3373 - precision: 0.8615 - recall: 0.8364\n",
            "Epoch 453/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3372 - precision: 0.8620 - recall: 0.8362\n",
            "Epoch 454/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3371 - precision: 0.8617 - recall: 0.8366\n",
            "Epoch 455/700\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.3370 - precision: 0.8620 - recall: 0.8363\n",
            "Epoch 456/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.3369 - precision: 0.8620 - recall: 0.8364\n",
            "Epoch 457/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3369 - precision: 0.8620 - recall: 0.8363\n",
            "Epoch 458/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.3368 - precision: 0.8624 - recall: 0.8360\n",
            "Epoch 459/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3367 - precision: 0.8625 - recall: 0.8360\n",
            "Epoch 460/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3366 - precision: 0.8626 - recall: 0.8358\n",
            "Epoch 461/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3365 - precision: 0.8626 - recall: 0.8359\n",
            "Epoch 462/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3364 - precision: 0.8626 - recall: 0.8362\n",
            "Epoch 463/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3363 - precision: 0.8624 - recall: 0.8363\n",
            "Epoch 464/700\n",
            "2/2 [==============================] - 1s 248ms/step - loss: 0.3362 - precision: 0.8623 - recall: 0.8364\n",
            "Epoch 465/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3361 - precision: 0.8623 - recall: 0.8366\n",
            "Epoch 466/700\n",
            "2/2 [==============================] - 1s 386ms/step - loss: 0.3360 - precision: 0.8625 - recall: 0.8365\n",
            "Epoch 467/700\n",
            "2/2 [==============================] - 1s 407ms/step - loss: 0.3359 - precision: 0.8624 - recall: 0.8366\n",
            "Epoch 468/700\n",
            "2/2 [==============================] - 1s 399ms/step - loss: 0.3358 - precision: 0.8625 - recall: 0.8364\n",
            "Epoch 469/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3357 - precision: 0.8629 - recall: 0.8362\n",
            "Epoch 470/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3356 - precision: 0.8628 - recall: 0.8365\n",
            "Epoch 471/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3356 - precision: 0.8629 - recall: 0.8366\n",
            "Epoch 472/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3355 - precision: 0.8626 - recall: 0.8367\n",
            "Epoch 473/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3354 - precision: 0.8629 - recall: 0.8367\n",
            "Epoch 474/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3353 - precision: 0.8630 - recall: 0.8367\n",
            "Epoch 475/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3352 - precision: 0.8630 - recall: 0.8368\n",
            "Epoch 476/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3351 - precision: 0.8633 - recall: 0.8364\n",
            "Epoch 477/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3350 - precision: 0.8631 - recall: 0.8369\n",
            "Epoch 478/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3349 - precision: 0.8631 - recall: 0.8368\n",
            "Epoch 479/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3348 - precision: 0.8635 - recall: 0.8366\n",
            "Epoch 480/700\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.3347 - precision: 0.8634 - recall: 0.8368\n",
            "Epoch 481/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3347 - precision: 0.8635 - recall: 0.8366\n",
            "Epoch 482/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3346 - precision: 0.8636 - recall: 0.8367\n",
            "Epoch 483/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3345 - precision: 0.8635 - recall: 0.8368\n",
            "Epoch 484/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3344 - precision: 0.8637 - recall: 0.8368\n",
            "Epoch 485/700\n",
            "2/2 [==============================] - 1s 402ms/step - loss: 0.3343 - precision: 0.8638 - recall: 0.8368\n",
            "Epoch 486/700\n",
            "2/2 [==============================] - 1s 396ms/step - loss: 0.3342 - precision: 0.8637 - recall: 0.8368\n",
            "Epoch 487/700\n",
            "2/2 [==============================] - 1s 391ms/step - loss: 0.3341 - precision: 0.8636 - recall: 0.8371\n",
            "Epoch 488/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3340 - precision: 0.8639 - recall: 0.8371\n",
            "Epoch 489/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3339 - precision: 0.8641 - recall: 0.8368\n",
            "Epoch 490/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3338 - precision: 0.8641 - recall: 0.8372\n",
            "Epoch 491/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3338 - precision: 0.8641 - recall: 0.8372\n",
            "Epoch 492/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3337 - precision: 0.8642 - recall: 0.8368\n",
            "Epoch 493/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.3336 - precision: 0.8642 - recall: 0.8370\n",
            "Epoch 494/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3335 - precision: 0.8642 - recall: 0.8373\n",
            "Epoch 495/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3334 - precision: 0.8643 - recall: 0.8368\n",
            "Epoch 496/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3333 - precision: 0.8642 - recall: 0.8372\n",
            "Epoch 497/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3332 - precision: 0.8643 - recall: 0.8372\n",
            "Epoch 498/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3331 - precision: 0.8643 - recall: 0.8372\n",
            "Epoch 499/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3330 - precision: 0.8643 - recall: 0.8372\n",
            "Epoch 500/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3329 - precision: 0.8643 - recall: 0.8374\n",
            "Epoch 501/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3329 - precision: 0.8643 - recall: 0.8375\n",
            "Epoch 502/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3328 - precision: 0.8641 - recall: 0.8378\n",
            "Epoch 503/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3327 - precision: 0.8645 - recall: 0.8371\n",
            "Epoch 504/700\n",
            "2/2 [==============================] - 1s 419ms/step - loss: 0.3326 - precision: 0.8642 - recall: 0.8375\n",
            "Epoch 505/700\n",
            "2/2 [==============================] - 1s 416ms/step - loss: 0.3325 - precision: 0.8644 - recall: 0.8372\n",
            "Epoch 506/700\n",
            "2/2 [==============================] - 1s 405ms/step - loss: 0.3324 - precision: 0.8648 - recall: 0.8370\n",
            "Epoch 507/700\n",
            "2/2 [==============================] - 1s 251ms/step - loss: 0.3323 - precision: 0.8648 - recall: 0.8370\n",
            "Epoch 508/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3322 - precision: 0.8649 - recall: 0.8372\n",
            "Epoch 509/700\n",
            "2/2 [==============================] - 1s 256ms/step - loss: 0.3322 - precision: 0.8654 - recall: 0.8368\n",
            "Epoch 510/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3321 - precision: 0.8652 - recall: 0.8368\n",
            "Epoch 511/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3320 - precision: 0.8649 - recall: 0.8372\n",
            "Epoch 512/700\n",
            "2/2 [==============================] - 1s 246ms/step - loss: 0.3319 - precision: 0.8651 - recall: 0.8372\n",
            "Epoch 513/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3318 - precision: 0.8648 - recall: 0.8377\n",
            "Epoch 514/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3317 - precision: 0.8649 - recall: 0.8377\n",
            "Epoch 515/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3316 - precision: 0.8650 - recall: 0.8375\n",
            "Epoch 516/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3315 - precision: 0.8650 - recall: 0.8378\n",
            "Epoch 517/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3315 - precision: 0.8650 - recall: 0.8375\n",
            "Epoch 518/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3314 - precision: 0.8651 - recall: 0.8375\n",
            "Epoch 519/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3313 - precision: 0.8654 - recall: 0.8374\n",
            "Epoch 520/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3312 - precision: 0.8656 - recall: 0.8370\n",
            "Epoch 521/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.3311 - precision: 0.8656 - recall: 0.8369\n",
            "Epoch 522/700\n",
            "2/2 [==============================] - 1s 322ms/step - loss: 0.3310 - precision: 0.8656 - recall: 0.8370\n",
            "Epoch 523/700\n",
            "2/2 [==============================] - 1s 415ms/step - loss: 0.3309 - precision: 0.8659 - recall: 0.8371\n",
            "Epoch 524/700\n",
            "2/2 [==============================] - 1s 400ms/step - loss: 0.3308 - precision: 0.8661 - recall: 0.8370\n",
            "Epoch 525/700\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.3308 - precision: 0.8657 - recall: 0.8374\n",
            "Epoch 526/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3307 - precision: 0.8661 - recall: 0.8372\n",
            "Epoch 527/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3306 - precision: 0.8659 - recall: 0.8376\n",
            "Epoch 528/700\n",
            "2/2 [==============================] - 1s 254ms/step - loss: 0.3305 - precision: 0.8656 - recall: 0.8381\n",
            "Epoch 529/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3304 - precision: 0.8655 - recall: 0.8383\n",
            "Epoch 530/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.3303 - precision: 0.8659 - recall: 0.8376\n",
            "Epoch 531/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.3302 - precision: 0.8658 - recall: 0.8377\n",
            "Epoch 532/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3302 - precision: 0.8663 - recall: 0.8374\n",
            "Epoch 533/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3301 - precision: 0.8663 - recall: 0.8377\n",
            "Epoch 534/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3300 - precision: 0.8665 - recall: 0.8377\n",
            "Epoch 535/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3299 - precision: 0.8667 - recall: 0.8372\n",
            "Epoch 536/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3298 - precision: 0.8668 - recall: 0.8374\n",
            "Epoch 537/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3297 - precision: 0.8667 - recall: 0.8377\n",
            "Epoch 538/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3296 - precision: 0.8670 - recall: 0.8375\n",
            "Epoch 539/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3296 - precision: 0.8669 - recall: 0.8377\n",
            "Epoch 540/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3295 - precision: 0.8670 - recall: 0.8379\n",
            "Epoch 541/700\n",
            "2/2 [==============================] - 1s 357ms/step - loss: 0.3294 - precision: 0.8670 - recall: 0.8379\n",
            "Epoch 542/700\n",
            "2/2 [==============================] - 1s 408ms/step - loss: 0.3293 - precision: 0.8672 - recall: 0.8379\n",
            "Epoch 543/700\n",
            "2/2 [==============================] - 1s 398ms/step - loss: 0.3292 - precision: 0.8671 - recall: 0.8379\n",
            "Epoch 544/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3291 - precision: 0.8671 - recall: 0.8377\n",
            "Epoch 545/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3290 - precision: 0.8673 - recall: 0.8379\n",
            "Epoch 546/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3290 - precision: 0.8671 - recall: 0.8381\n",
            "Epoch 547/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3289 - precision: 0.8673 - recall: 0.8379\n",
            "Epoch 548/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3288 - precision: 0.8671 - recall: 0.8379\n",
            "Epoch 549/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3287 - precision: 0.8672 - recall: 0.8377\n",
            "Epoch 550/700\n",
            "2/2 [==============================] - 1s 206ms/step - loss: 0.3286 - precision: 0.8672 - recall: 0.8381\n",
            "Epoch 551/700\n",
            "2/2 [==============================] - 1s 217ms/step - loss: 0.3285 - precision: 0.8672 - recall: 0.8380\n",
            "Epoch 552/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3285 - precision: 0.8674 - recall: 0.8380\n",
            "Epoch 553/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3284 - precision: 0.8673 - recall: 0.8381\n",
            "Epoch 554/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3283 - precision: 0.8674 - recall: 0.8382\n",
            "Epoch 555/700\n",
            "2/2 [==============================] - 1s 211ms/step - loss: 0.3282 - precision: 0.8673 - recall: 0.8385\n",
            "Epoch 556/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3281 - precision: 0.8676 - recall: 0.8383\n",
            "Epoch 557/700\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.3280 - precision: 0.8676 - recall: 0.8383\n",
            "Epoch 558/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3279 - precision: 0.8676 - recall: 0.8386\n",
            "Epoch 559/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3279 - precision: 0.8675 - recall: 0.8386\n",
            "Epoch 560/700\n",
            "2/2 [==============================] - 1s 282ms/step - loss: 0.3278 - precision: 0.8677 - recall: 0.8387\n",
            "Epoch 561/700\n",
            "2/2 [==============================] - 1s 417ms/step - loss: 0.3277 - precision: 0.8677 - recall: 0.8387\n",
            "Epoch 562/700\n",
            "2/2 [==============================] - 1s 407ms/step - loss: 0.3276 - precision: 0.8677 - recall: 0.8387\n",
            "Epoch 563/700\n",
            "2/2 [==============================] - 1s 269ms/step - loss: 0.3275 - precision: 0.8678 - recall: 0.8388\n",
            "Epoch 564/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.3274 - precision: 0.8678 - recall: 0.8390\n",
            "Epoch 565/700\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3274 - precision: 0.8678 - recall: 0.8389\n",
            "Epoch 566/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3273 - precision: 0.8677 - recall: 0.8391\n",
            "Epoch 567/700\n",
            "2/2 [==============================] - 1s 209ms/step - loss: 0.3272 - precision: 0.8679 - recall: 0.8390\n",
            "Epoch 568/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3271 - precision: 0.8681 - recall: 0.8390\n",
            "Epoch 569/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.3270 - precision: 0.8681 - recall: 0.8389\n",
            "Epoch 570/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3269 - precision: 0.8682 - recall: 0.8391\n",
            "Epoch 571/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3269 - precision: 0.8681 - recall: 0.8392\n",
            "Epoch 572/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3268 - precision: 0.8682 - recall: 0.8387\n",
            "Epoch 573/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3267 - precision: 0.8684 - recall: 0.8387\n",
            "Epoch 574/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3266 - precision: 0.8686 - recall: 0.8386\n",
            "Epoch 575/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3265 - precision: 0.8687 - recall: 0.8387\n",
            "Epoch 576/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3264 - precision: 0.8685 - recall: 0.8388\n",
            "Epoch 577/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3264 - precision: 0.8687 - recall: 0.8389\n",
            "Epoch 578/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3263 - precision: 0.8686 - recall: 0.8389\n",
            "Epoch 579/700\n",
            "2/2 [==============================] - 1s 253ms/step - loss: 0.3262 - precision: 0.8689 - recall: 0.8389\n",
            "Epoch 580/700\n",
            "2/2 [==============================] - 1s 395ms/step - loss: 0.3261 - precision: 0.8689 - recall: 0.8388\n",
            "Epoch 581/700\n",
            "2/2 [==============================] - 1s 398ms/step - loss: 0.3260 - precision: 0.8686 - recall: 0.8395\n",
            "Epoch 582/700\n",
            "2/2 [==============================] - 1s 356ms/step - loss: 0.3259 - precision: 0.8690 - recall: 0.8389\n",
            "Epoch 583/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3259 - precision: 0.8690 - recall: 0.8393\n",
            "Epoch 584/700\n",
            "2/2 [==============================] - 1s 219ms/step - loss: 0.3258 - precision: 0.8690 - recall: 0.8393\n",
            "Epoch 585/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3257 - precision: 0.8691 - recall: 0.8395\n",
            "Epoch 586/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3256 - precision: 0.8690 - recall: 0.8393\n",
            "Epoch 587/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3255 - precision: 0.8692 - recall: 0.8394\n",
            "Epoch 588/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3255 - precision: 0.8692 - recall: 0.8394\n",
            "Epoch 589/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3254 - precision: 0.8695 - recall: 0.8393\n",
            "Epoch 590/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3253 - precision: 0.8692 - recall: 0.8393\n",
            "Epoch 591/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3252 - precision: 0.8697 - recall: 0.8393\n",
            "Epoch 592/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3251 - precision: 0.8695 - recall: 0.8395\n",
            "Epoch 593/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3250 - precision: 0.8702 - recall: 0.8389\n",
            "Epoch 594/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3250 - precision: 0.8701 - recall: 0.8392\n",
            "Epoch 595/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3249 - precision: 0.8700 - recall: 0.8393\n",
            "Epoch 596/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3248 - precision: 0.8701 - recall: 0.8391\n",
            "Epoch 597/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3247 - precision: 0.8702 - recall: 0.8392\n",
            "Epoch 598/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3246 - precision: 0.8704 - recall: 0.8393\n",
            "Epoch 599/700\n",
            "2/2 [==============================] - 1s 428ms/step - loss: 0.3245 - precision: 0.8703 - recall: 0.8395\n",
            "Epoch 600/700\n",
            "2/2 [==============================] - 1s 397ms/step - loss: 0.3245 - precision: 0.8702 - recall: 0.8399\n",
            "Epoch 601/700\n",
            "2/2 [==============================] - 1s 374ms/step - loss: 0.3244 - precision: 0.8704 - recall: 0.8394\n",
            "Epoch 602/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3243 - precision: 0.8703 - recall: 0.8398\n",
            "Epoch 603/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3242 - precision: 0.8704 - recall: 0.8398\n",
            "Epoch 604/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3241 - precision: 0.8705 - recall: 0.8397\n",
            "Epoch 605/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3241 - precision: 0.8704 - recall: 0.8398\n",
            "Epoch 606/700\n",
            "2/2 [==============================] - 1s 254ms/step - loss: 0.3240 - precision: 0.8707 - recall: 0.8394\n",
            "Epoch 607/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3239 - precision: 0.8706 - recall: 0.8398\n",
            "Epoch 608/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3238 - precision: 0.8707 - recall: 0.8395\n",
            "Epoch 609/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3237 - precision: 0.8708 - recall: 0.8398\n",
            "Epoch 610/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3237 - precision: 0.8708 - recall: 0.8399\n",
            "Epoch 611/700\n",
            "2/2 [==============================] - 1s 243ms/step - loss: 0.3236 - precision: 0.8708 - recall: 0.8398\n",
            "Epoch 612/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3235 - precision: 0.8708 - recall: 0.8406\n",
            "Epoch 613/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.3234 - precision: 0.8709 - recall: 0.8402\n",
            "Epoch 614/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3233 - precision: 0.8708 - recall: 0.8400\n",
            "Epoch 615/700\n",
            "2/2 [==============================] - 1s 210ms/step - loss: 0.3233 - precision: 0.8709 - recall: 0.8406\n",
            "Epoch 616/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3232 - precision: 0.8710 - recall: 0.8400\n",
            "Epoch 617/700\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.3231 - precision: 0.8711 - recall: 0.8404\n",
            "Epoch 618/700\n",
            "2/2 [==============================] - 1s 421ms/step - loss: 0.3230 - precision: 0.8712 - recall: 0.8405\n",
            "Epoch 619/700\n",
            "2/2 [==============================] - 1s 368ms/step - loss: 0.3229 - precision: 0.8715 - recall: 0.8400\n",
            "Epoch 620/700\n",
            "2/2 [==============================] - 1s 382ms/step - loss: 0.3228 - precision: 0.8713 - recall: 0.8404\n",
            "Epoch 621/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3228 - precision: 0.8714 - recall: 0.8405\n",
            "Epoch 622/700\n",
            "2/2 [==============================] - 1s 250ms/step - loss: 0.3227 - precision: 0.8718 - recall: 0.8404\n",
            "Epoch 623/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3226 - precision: 0.8716 - recall: 0.8406\n",
            "Epoch 624/700\n",
            "2/2 [==============================] - 1s 230ms/step - loss: 0.3225 - precision: 0.8719 - recall: 0.8407\n",
            "Epoch 625/700\n",
            "2/2 [==============================] - 1s 254ms/step - loss: 0.3224 - precision: 0.8719 - recall: 0.8408\n",
            "Epoch 626/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3224 - precision: 0.8719 - recall: 0.8408\n",
            "Epoch 627/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3223 - precision: 0.8720 - recall: 0.8410\n",
            "Epoch 628/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3222 - precision: 0.8720 - recall: 0.8411\n",
            "Epoch 629/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3221 - precision: 0.8720 - recall: 0.8410\n",
            "Epoch 630/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3220 - precision: 0.8721 - recall: 0.8412\n",
            "Epoch 631/700\n",
            "2/2 [==============================] - 1s 212ms/step - loss: 0.3220 - precision: 0.8721 - recall: 0.8412\n",
            "Epoch 632/700\n",
            "2/2 [==============================] - 1s 236ms/step - loss: 0.3219 - precision: 0.8722 - recall: 0.8412\n",
            "Epoch 633/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3218 - precision: 0.8721 - recall: 0.8410\n",
            "Epoch 634/700\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3217 - precision: 0.8720 - recall: 0.8416\n",
            "Epoch 635/700\n",
            "2/2 [==============================] - 1s 244ms/step - loss: 0.3217 - precision: 0.8721 - recall: 0.8416\n",
            "Epoch 636/700\n",
            "2/2 [==============================] - 1s 216ms/step - loss: 0.3216 - precision: 0.8721 - recall: 0.8421\n",
            "Epoch 637/700\n",
            "2/2 [==============================] - 1s 404ms/step - loss: 0.3215 - precision: 0.8724 - recall: 0.8412\n",
            "Epoch 638/700\n",
            "2/2 [==============================] - 1s 407ms/step - loss: 0.3214 - precision: 0.8724 - recall: 0.8416\n",
            "Epoch 639/700\n",
            "2/2 [==============================] - 1s 410ms/step - loss: 0.3213 - precision: 0.8725 - recall: 0.8412\n",
            "Epoch 640/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3213 - precision: 0.8724 - recall: 0.8414\n",
            "Epoch 641/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3212 - precision: 0.8728 - recall: 0.8411\n",
            "Epoch 642/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3211 - precision: 0.8729 - recall: 0.8411\n",
            "Epoch 643/700\n",
            "2/2 [==============================] - 1s 247ms/step - loss: 0.3210 - precision: 0.8728 - recall: 0.8413\n",
            "Epoch 644/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3209 - precision: 0.8727 - recall: 0.8414\n",
            "Epoch 645/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3209 - precision: 0.8728 - recall: 0.8414\n",
            "Epoch 646/700\n",
            "2/2 [==============================] - 1s 239ms/step - loss: 0.3208 - precision: 0.8728 - recall: 0.8412\n",
            "Epoch 647/700\n",
            "2/2 [==============================] - 1s 215ms/step - loss: 0.3207 - precision: 0.8728 - recall: 0.8414\n",
            "Epoch 648/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3206 - precision: 0.8728 - recall: 0.8414\n",
            "Epoch 649/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3205 - precision: 0.8728 - recall: 0.8416\n",
            "Epoch 650/700\n",
            "2/2 [==============================] - 1s 240ms/step - loss: 0.3205 - precision: 0.8729 - recall: 0.8416\n",
            "Epoch 651/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3204 - precision: 0.8729 - recall: 0.8419\n",
            "Epoch 652/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3203 - precision: 0.8730 - recall: 0.8414\n",
            "Epoch 653/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3202 - precision: 0.8731 - recall: 0.8416\n",
            "Epoch 654/700\n",
            "2/2 [==============================] - 1s 238ms/step - loss: 0.3201 - precision: 0.8731 - recall: 0.8418\n",
            "Epoch 655/700\n",
            "2/2 [==============================] - 1s 369ms/step - loss: 0.3201 - precision: 0.8730 - recall: 0.8417\n",
            "Epoch 656/700\n",
            "2/2 [==============================] - 1s 392ms/step - loss: 0.3200 - precision: 0.8730 - recall: 0.8418\n",
            "Epoch 657/700\n",
            "2/2 [==============================] - 1s 397ms/step - loss: 0.3199 - precision: 0.8731 - recall: 0.8415\n",
            "Epoch 658/700\n",
            "2/2 [==============================] - 1s 249ms/step - loss: 0.3198 - precision: 0.8732 - recall: 0.8418\n",
            "Epoch 659/700\n",
            "2/2 [==============================] - 1s 237ms/step - loss: 0.3198 - precision: 0.8732 - recall: 0.8417\n",
            "Epoch 660/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3197 - precision: 0.8733 - recall: 0.8419\n",
            "Epoch 661/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3196 - precision: 0.8733 - recall: 0.8417\n",
            "Epoch 662/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3195 - precision: 0.8732 - recall: 0.8419\n",
            "Epoch 663/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3194 - precision: 0.8733 - recall: 0.8420\n",
            "Epoch 664/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3194 - precision: 0.8734 - recall: 0.8418\n",
            "Epoch 665/700\n",
            "2/2 [==============================] - 1s 242ms/step - loss: 0.3193 - precision: 0.8735 - recall: 0.8417\n",
            "Epoch 666/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3192 - precision: 0.8735 - recall: 0.8421\n",
            "Epoch 667/700\n",
            "2/2 [==============================] - 1s 222ms/step - loss: 0.3191 - precision: 0.8735 - recall: 0.8418\n",
            "Epoch 668/700\n",
            "2/2 [==============================] - 1s 229ms/step - loss: 0.3190 - precision: 0.8738 - recall: 0.8421\n",
            "Epoch 669/700\n",
            "2/2 [==============================] - 1s 224ms/step - loss: 0.3190 - precision: 0.8739 - recall: 0.8421\n",
            "Epoch 670/700\n",
            "2/2 [==============================] - 1s 226ms/step - loss: 0.3189 - precision: 0.8742 - recall: 0.8421\n",
            "Epoch 671/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3188 - precision: 0.8739 - recall: 0.8423\n",
            "Epoch 672/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3187 - precision: 0.8740 - recall: 0.8423\n",
            "Epoch 673/700\n",
            "2/2 [==============================] - 1s 244ms/step - loss: 0.3187 - precision: 0.8739 - recall: 0.8425\n",
            "Epoch 674/700\n",
            "2/2 [==============================] - 1s 366ms/step - loss: 0.3186 - precision: 0.8741 - recall: 0.8423\n",
            "Epoch 675/700\n",
            "2/2 [==============================] - 1s 385ms/step - loss: 0.3185 - precision: 0.8744 - recall: 0.8425\n",
            "Epoch 676/700\n",
            "2/2 [==============================] - 1s 388ms/step - loss: 0.3184 - precision: 0.8742 - recall: 0.8425\n",
            "Epoch 677/700\n",
            "2/2 [==============================] - 1s 225ms/step - loss: 0.3183 - precision: 0.8743 - recall: 0.8424\n",
            "Epoch 678/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3183 - precision: 0.8743 - recall: 0.8425\n",
            "Epoch 679/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3182 - precision: 0.8742 - recall: 0.8426\n",
            "Epoch 680/700\n",
            "2/2 [==============================] - 1s 221ms/step - loss: 0.3181 - precision: 0.8743 - recall: 0.8427\n",
            "Epoch 681/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3180 - precision: 0.8743 - recall: 0.8427\n",
            "Epoch 682/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3180 - precision: 0.8743 - recall: 0.8428\n",
            "Epoch 683/700\n",
            "2/2 [==============================] - 1s 228ms/step - loss: 0.3179 - precision: 0.8741 - recall: 0.8429\n",
            "Epoch 684/700\n",
            "2/2 [==============================] - 1s 232ms/step - loss: 0.3178 - precision: 0.8744 - recall: 0.8431\n",
            "Epoch 685/700\n",
            "2/2 [==============================] - 1s 220ms/step - loss: 0.3177 - precision: 0.8743 - recall: 0.8431\n",
            "Epoch 686/700\n",
            "2/2 [==============================] - 1s 235ms/step - loss: 0.3177 - precision: 0.8746 - recall: 0.8429\n",
            "Epoch 687/700\n",
            "2/2 [==============================] - 1s 245ms/step - loss: 0.3176 - precision: 0.8746 - recall: 0.8435\n",
            "Epoch 688/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3175 - precision: 0.8748 - recall: 0.8433\n",
            "Epoch 689/700\n",
            "2/2 [==============================] - 1s 233ms/step - loss: 0.3174 - precision: 0.8750 - recall: 0.8428\n",
            "Epoch 690/700\n",
            "2/2 [==============================] - 1s 214ms/step - loss: 0.3173 - precision: 0.8749 - recall: 0.8434\n",
            "Epoch 691/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3173 - precision: 0.8751 - recall: 0.8430\n",
            "Epoch 692/700\n",
            "2/2 [==============================] - 1s 241ms/step - loss: 0.3172 - precision: 0.8751 - recall: 0.8437\n",
            "Epoch 693/700\n",
            "2/2 [==============================] - 1s 397ms/step - loss: 0.3171 - precision: 0.8752 - recall: 0.8435\n",
            "Epoch 694/700\n",
            "2/2 [==============================] - 1s 325ms/step - loss: 0.3170 - precision: 0.8750 - recall: 0.8437\n",
            "Epoch 695/700\n",
            "2/2 [==============================] - 1s 380ms/step - loss: 0.3169 - precision: 0.8752 - recall: 0.8440\n",
            "Epoch 696/700\n",
            "2/2 [==============================] - 1s 227ms/step - loss: 0.3169 - precision: 0.8753 - recall: 0.8439\n",
            "Epoch 697/700\n",
            "2/2 [==============================] - 1s 231ms/step - loss: 0.3168 - precision: 0.8753 - recall: 0.8437\n",
            "Epoch 698/700\n",
            "2/2 [==============================] - 1s 234ms/step - loss: 0.3167 - precision: 0.8754 - recall: 0.8437\n",
            "Epoch 699/700\n",
            "2/2 [==============================] - 1s 218ms/step - loss: 0.3166 - precision: 0.8757 - recall: 0.8437\n",
            "Epoch 700/700\n",
            "2/2 [==============================] - 1s 223ms/step - loss: 0.3166 - precision: 0.8756 - recall: 0.8440\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c9280329030>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see on the last steps that the precision and recall are not improving anymore, so we are sure the model has done everything it can do at this point. Now I evaluate the test set."
      ],
      "metadata": {
        "id": "_mP7CE7pAzw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_out = neur.predict(x_finaleval)\n",
        "test_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "012fZOcVAzZQ",
        "outputId": "c0488532-2747-4f8c-d783-80f977059a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "419/419 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4310239 ],\n",
              "       [0.93514055],\n",
              "       [0.18660098],\n",
              "       ...,\n",
              "       [0.9413881 ],\n",
              "       [0.03979347],\n",
              "       [0.8253069 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final result (Offensive language)"
      ],
      "metadata": {
        "id": "quqe0zq5o961"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = outp[1][[0]]\n",
        "scal = MinMaxScaler()\n",
        "output['predicted'] = scal.fit_transform(test_out)\n",
        "output['actual'] = y_finaleval\n",
        "output = output.drop(columns=[0])\n",
        "output = pd.merge(output, maindataset[['index','tweet']], left_index=True, right_on=['index'])\n",
        "output = output.sort_values(['predicted'], ascending=False)\n",
        "pd.options.display.max_colwidth = 150\n",
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "myYlirq9BFrP",
        "outputId": "d4e536f6-4cce-4527-fb5e-73d09dd06e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          predicted  actual  index  \\\n",
              "15222  9.999999e-01       1  15384   \n",
              "13159  9.999971e-01       1  13315   \n",
              "478    9.999969e-01       1    478   \n",
              "18073  9.999919e-01       1  18235   \n",
              "10802  9.999889e-01       1  10945   \n",
              "...             ...     ...    ...   \n",
              "27143  6.846691e-05       0  27362   \n",
              "33819  5.055554e-05       0  34041   \n",
              "35521  1.446507e-05       0  35748   \n",
              "30979  1.954322e-07       0  31200   \n",
              "25388  0.000000e+00       0  25606   \n",
              "\n",
              "                                                                                                                                                       tweet  \n",
              "15222  RT @GrownAssMidget: I&#8217;m a bitch? You&#8217;re a bitch. Your mom&#8217;s a bitch for having a bitch, your dad&#8217;s a bitch for fucking a b...  \n",
              "13159                                                                                                Niggas be bitches hoes be bitches ion see no difference  \n",
              "478                                        \"I had a bitch that had a bitch, had the bitch eating halibut..\" - @iamyoungroc #FreshRhymes #JerkSquad #SlowStir  \n",
              "18073                                                                    RT @_2kkz: This faggit bitch tried to say she hoe'd for hd bearfaced bitch yusa fag  \n",
              "10802                                                                         I tell the 5th bitch to get the 6th bitch to to have the 7th bitch bring more.  \n",
              "...                                                                                                                                                      ...  \n",
              "27143                                                             ÛÏPoetry is eternal graffiti written in the heart of everyone.Û https://t.co/Lj4WLpgmPm  \n",
              "33819                                                                         the third chapter of head over heels has been updated! https://t.co/uYAVU6QH1X  \n",
              "35521            General Mills - Source Greek Snack Bowl - 12g Of Protein And 50% ... - https://t.co/6T7KOKBVUn - #tvcommercialspots https://t.co/j4DdX6PLve  \n",
              "30979                                  Skyscrapers are NOT ruining the London skyline claims The Shard architect Renzo Piano #UkNews https://t.co/AOWVgTUFk3  \n",
              "25388                              You're invited to read #free chapters! THE PIRATE AND THE AMBER CAT #romance #clean #pirate #teen https://t.co/fKTgDcU4EU  \n",
              "\n",
              "[13381 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c935a91-afd3-448d-890d-39cac8f11076\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15222</th>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>1</td>\n",
              "      <td>15384</td>\n",
              "      <td>RT @GrownAssMidget: I&amp;#8217;m a bitch? You&amp;#8217;re a bitch. Your mom&amp;#8217;s a bitch for having a bitch, your dad&amp;#8217;s a bitch for fucking a b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13159</th>\n",
              "      <td>9.999971e-01</td>\n",
              "      <td>1</td>\n",
              "      <td>13315</td>\n",
              "      <td>Niggas be bitches hoes be bitches ion see no difference</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>9.999969e-01</td>\n",
              "      <td>1</td>\n",
              "      <td>478</td>\n",
              "      <td>\"I had a bitch that had a bitch, had the bitch eating halibut..\" - @iamyoungroc #FreshRhymes #JerkSquad #SlowStir</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18073</th>\n",
              "      <td>9.999919e-01</td>\n",
              "      <td>1</td>\n",
              "      <td>18235</td>\n",
              "      <td>RT @_2kkz: This faggit bitch tried to say she hoe'd for hd bearfaced bitch yusa fag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10802</th>\n",
              "      <td>9.999889e-01</td>\n",
              "      <td>1</td>\n",
              "      <td>10945</td>\n",
              "      <td>I tell the 5th bitch to get the 6th bitch to to have the 7th bitch bring more.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27143</th>\n",
              "      <td>6.846691e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>27362</td>\n",
              "      <td>ÛÏPoetry is eternal graffiti written in the heart of everyone.Û https://t.co/Lj4WLpgmPm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33819</th>\n",
              "      <td>5.055554e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>34041</td>\n",
              "      <td>the third chapter of head over heels has been updated! https://t.co/uYAVU6QH1X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35521</th>\n",
              "      <td>1.446507e-05</td>\n",
              "      <td>0</td>\n",
              "      <td>35748</td>\n",
              "      <td>General Mills - Source Greek Snack Bowl - 12g Of Protein And 50% ... - https://t.co/6T7KOKBVUn - #tvcommercialspots https://t.co/j4DdX6PLve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30979</th>\n",
              "      <td>1.954322e-07</td>\n",
              "      <td>0</td>\n",
              "      <td>31200</td>\n",
              "      <td>Skyscrapers are NOT ruining the London skyline claims The Shard architect Renzo Piano #UkNews https://t.co/AOWVgTUFk3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25388</th>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0</td>\n",
              "      <td>25606</td>\n",
              "      <td>You're invited to read #free chapters! THE PIRATE AND THE AMBER CAT #romance #clean #pirate #teen https://t.co/fKTgDcU4EU</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13381 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c935a91-afd3-448d-890d-39cac8f11076')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5c935a91-afd3-448d-890d-39cac8f11076 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5c935a91-afd3-448d-890d-39cac8f11076');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e487c292-6512-49b7-b2e5-3b4b0699af99\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e487c292-6512-49b7-b2e5-3b4b0699af99')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e487c292-6512-49b7-b2e5-3b4b0699af99 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix (cut point at 0.5)"
      ],
      "metadata": {
        "id": "i2nf8SWls3P3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output[\"predictedVal\"] = np.where(output['predicted']>=0.5,1,0)\n",
        "print(classification_report(output['actual'],output[\"predictedVal\"] ))\n",
        "ConfusionMatrixDisplay.from_predictions(y_true=output['actual'] ,y_pred=output['predictedVal'] , cmap='PuBu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "czsp7TTGs6sc",
        "outputId": "9322ac74-5ed6-4cad-f620-3d4ec59ea585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.88      0.86      7034\n",
            "           1       0.86      0.83      0.84      6347\n",
            "\n",
            "    accuracy                           0.85     13381\n",
            "   macro avg       0.85      0.85      0.85     13381\n",
            "weighted avg       0.85      0.85      0.85     13381\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7c9281ed0a90>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the same approach now for hate speech:"
      ],
      "metadata": {
        "id": "Lnxlu2WspJk0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasetR['target'] = maindataset['hate_speech'].values\n",
        "\n",
        "outp = train_test_split(datasetR, train_size=0.7)\n",
        "finaleval=outp[1]\n",
        "subset=outp[0]\n",
        "\n",
        "x_subset = subset.drop(columns=[\"target\"]).to_numpy()\n",
        "y_subset = subset['target'].to_numpy()\n",
        "x_finaleval = finaleval.drop(columns=[\"target\"]).to_numpy()\n",
        "y_finaleval = finaleval[['target']].to_numpy()\n",
        "#size of the training set\n",
        "print(len(y_subset))\n",
        "sns.displot(y_subset)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "TQP6Vkz7nXK6",
        "outputId": "79732be4-9f2e-4c7f-a837-dfdc2c4649ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7c92834c8730>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classes are highly unbalanced, the next step is used to rebalance the classes"
      ],
      "metadata": {
        "id": "LuN9dRWxuGUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rebalance(sset, min, max):\n",
        " classes = list(set(sset[\"target\"]))\n",
        " a = []\n",
        " for clas in classes:\n",
        "  positives = sset[sset['target']==clas]\n",
        "  if len(positives) < min:\n",
        "   positives = resample(positives, n_samples=min, replace=True)\n",
        "  if len(positives) > max:\n",
        "   positives = resample(positives, n_samples=max, replace=False)\n",
        "  a.append(positives)\n",
        " rebalanced = pd.concat(a, axis=0, ignore_index=True)\n",
        " return rebalanced\n",
        "\n",
        "subsetR = rebalance(sset=subset, min=round(5000), max=round(7000))\n",
        "\n",
        "x_subset = subsetR.drop(columns=[\"target\"]).to_numpy()\n",
        "y_subset = subsetR['target'].to_numpy()\n",
        "print(len(y_subset))\n",
        "sns.displot(y_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "zXNybv1gvPim",
        "outputId": "e1f14d53-35a0-432b-bbb6-3facd8be0830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7c92805d1930>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize\n",
        "neur = tf.keras.models.Sequential()\n",
        "#layers\n",
        "neur.add(tf.keras.layers.Dense(units=100, activation='linear'))\n",
        "neur.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
        "neur.add(tf.keras.layers.Dense(units=500, activation='tanh'))\n",
        "\n",
        "#output layer\n",
        "neur.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "#using mse for regression. Simple and clear\n",
        "neur.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
        "\n",
        "neur.fit(x_subset, y_subset, batch_size=10000, epochs=700)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aB8AIEP5pdIK",
        "outputId": "911e1245-af09-4f08-c2ab-9c01ac1b622b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/700\n",
            "2/2 [==============================] - 1s 49ms/step - loss: 0.7491 - precision_6: 0.3953 - recall_6: 0.5716\n",
            "Epoch 2/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.7331 - precision_6: 0.4023 - recall_6: 0.4904\n",
            "Epoch 3/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.7224 - precision_6: 0.4123 - recall_6: 0.4328\n",
            "Epoch 4/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.7147 - precision_6: 0.4238 - recall_6: 0.3896\n",
            "Epoch 5/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.7085 - precision_6: 0.4319 - recall_6: 0.3570\n",
            "Epoch 6/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7035 - precision_6: 0.4443 - recall_6: 0.3516\n",
            "Epoch 7/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6988 - precision_6: 0.4529 - recall_6: 0.3454\n",
            "Epoch 8/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6944 - precision_6: 0.4665 - recall_6: 0.3440\n",
            "Epoch 9/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.6904 - precision_6: 0.4801 - recall_6: 0.3328\n",
            "Epoch 10/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6867 - precision_6: 0.4876 - recall_6: 0.3336\n",
            "Epoch 11/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.6833 - precision_6: 0.4943 - recall_6: 0.3368\n",
            "Epoch 12/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6800 - precision_6: 0.5051 - recall_6: 0.3368\n",
            "Epoch 13/700\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.6768 - precision_6: 0.5167 - recall_6: 0.3370\n",
            "Epoch 14/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6739 - precision_6: 0.5268 - recall_6: 0.3406\n",
            "Epoch 15/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.6711 - precision_6: 0.5316 - recall_6: 0.3520\n",
            "Epoch 16/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6685 - precision_6: 0.5385 - recall_6: 0.3570\n",
            "Epoch 17/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.6660 - precision_6: 0.5476 - recall_6: 0.3578\n",
            "Epoch 18/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6636 - precision_6: 0.5536 - recall_6: 0.3636\n",
            "Epoch 19/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.6612 - precision_6: 0.5569 - recall_6: 0.3766\n",
            "Epoch 20/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6588 - precision_6: 0.5590 - recall_6: 0.3808\n",
            "Epoch 21/700\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.6566 - precision_6: 0.5603 - recall_6: 0.3900\n",
            "Epoch 22/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.6545 - precision_6: 0.5642 - recall_6: 0.3876\n",
            "Epoch 23/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.6525 - precision_6: 0.5686 - recall_6: 0.3986\n",
            "Epoch 24/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.6506 - precision_6: 0.5688 - recall_6: 0.4166\n",
            "Epoch 25/700\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.6487 - precision_6: 0.5745 - recall_6: 0.4140\n",
            "Epoch 26/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.6469 - precision_6: 0.5782 - recall_6: 0.4156\n",
            "Epoch 27/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.6452 - precision_6: 0.5817 - recall_6: 0.4138\n",
            "Epoch 28/700\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.6435 - precision_6: 0.5863 - recall_6: 0.4220\n",
            "Epoch 29/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.6419 - precision_6: 0.5908 - recall_6: 0.4244\n",
            "Epoch 30/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.6403 - precision_6: 0.5953 - recall_6: 0.4198\n",
            "Epoch 31/700\n",
            "2/2 [==============================] - 1s 118ms/step - loss: 0.6388 - precision_6: 0.5966 - recall_6: 0.4298\n",
            "Epoch 32/700\n",
            "2/2 [==============================] - 0s 117ms/step - loss: 0.6373 - precision_6: 0.6005 - recall_6: 0.4416\n",
            "Epoch 33/700\n",
            "2/2 [==============================] - 1s 113ms/step - loss: 0.6359 - precision_6: 0.6036 - recall_6: 0.4318\n",
            "Epoch 34/700\n",
            "2/2 [==============================] - 1s 131ms/step - loss: 0.6344 - precision_6: 0.6046 - recall_6: 0.4480\n",
            "Epoch 35/700\n",
            "2/2 [==============================] - 1s 161ms/step - loss: 0.6330 - precision_6: 0.6083 - recall_6: 0.4492\n",
            "Epoch 36/700\n",
            "2/2 [==============================] - 1s 103ms/step - loss: 0.6317 - precision_6: 0.6097 - recall_6: 0.4608\n",
            "Epoch 37/700\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.6303 - precision_6: 0.6118 - recall_6: 0.4586\n",
            "Epoch 38/700\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.6290 - precision_6: 0.6136 - recall_6: 0.4650\n",
            "Epoch 39/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.6277 - precision_6: 0.6138 - recall_6: 0.4666\n",
            "Epoch 40/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.6265 - precision_6: 0.6151 - recall_6: 0.4692\n",
            "Epoch 41/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.6253 - precision_6: 0.6147 - recall_6: 0.4786\n",
            "Epoch 42/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.6242 - precision_6: 0.6172 - recall_6: 0.4808\n",
            "Epoch 43/700\n",
            "2/2 [==============================] - 0s 116ms/step - loss: 0.6230 - precision_6: 0.6212 - recall_6: 0.4822\n",
            "Epoch 44/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.6218 - precision_6: 0.6251 - recall_6: 0.4776\n",
            "Epoch 45/700\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.6207 - precision_6: 0.6258 - recall_6: 0.4850\n",
            "Epoch 46/700\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.6196 - precision_6: 0.6262 - recall_6: 0.4818\n",
            "Epoch 47/700\n",
            "2/2 [==============================] - 0s 97ms/step - loss: 0.6186 - precision_6: 0.6276 - recall_6: 0.4830\n",
            "Epoch 48/700\n",
            "2/2 [==============================] - 1s 137ms/step - loss: 0.6175 - precision_6: 0.6292 - recall_6: 0.4812\n",
            "Epoch 49/700\n",
            "2/2 [==============================] - 1s 140ms/step - loss: 0.6165 - precision_6: 0.6307 - recall_6: 0.4816\n",
            "Epoch 50/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6155 - precision_6: 0.6325 - recall_6: 0.4826\n",
            "Epoch 51/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.6144 - precision_6: 0.6348 - recall_6: 0.4880\n",
            "Epoch 52/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6135 - precision_6: 0.6402 - recall_6: 0.4798\n",
            "Epoch 53/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6125 - precision_6: 0.6427 - recall_6: 0.4838\n",
            "Epoch 54/700\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.6116 - precision_6: 0.6432 - recall_6: 0.4860\n",
            "Epoch 55/700\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.6107 - precision_6: 0.6435 - recall_6: 0.4896\n",
            "Epoch 56/700\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.6097 - precision_6: 0.6451 - recall_6: 0.4890\n",
            "Epoch 57/700\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.6088 - precision_6: 0.6455 - recall_6: 0.5000\n",
            "Epoch 58/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.6079 - precision_6: 0.6463 - recall_6: 0.5026\n",
            "Epoch 59/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.6071 - precision_6: 0.6471 - recall_6: 0.5032\n",
            "Epoch 60/700\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.6062 - precision_6: 0.6500 - recall_6: 0.5014\n",
            "Epoch 61/700\n",
            "2/2 [==============================] - 0s 136ms/step - loss: 0.6053 - precision_6: 0.6484 - recall_6: 0.5086\n",
            "Epoch 62/700\n",
            "2/2 [==============================] - 1s 132ms/step - loss: 0.6045 - precision_6: 0.6502 - recall_6: 0.5112\n",
            "Epoch 63/700\n",
            "2/2 [==============================] - 1s 118ms/step - loss: 0.6037 - precision_6: 0.6508 - recall_6: 0.5110\n",
            "Epoch 64/700\n",
            "2/2 [==============================] - 1s 142ms/step - loss: 0.6029 - precision_6: 0.6516 - recall_6: 0.5116\n",
            "Epoch 65/700\n",
            "2/2 [==============================] - 1s 159ms/step - loss: 0.6020 - precision_6: 0.6521 - recall_6: 0.5118\n",
            "Epoch 66/700\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.6012 - precision_6: 0.6539 - recall_6: 0.5098\n",
            "Epoch 67/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.6004 - precision_6: 0.6549 - recall_6: 0.5128\n",
            "Epoch 68/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.5997 - precision_6: 0.6556 - recall_6: 0.5178\n",
            "Epoch 69/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5989 - precision_6: 0.6577 - recall_6: 0.5164\n",
            "Epoch 70/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5981 - precision_6: 0.6602 - recall_6: 0.5090\n",
            "Epoch 71/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.5973 - precision_6: 0.6589 - recall_6: 0.5172\n",
            "Epoch 72/700\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.5966 - precision_6: 0.6590 - recall_6: 0.5182\n",
            "Epoch 73/700\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5958 - precision_6: 0.6611 - recall_6: 0.5182\n",
            "Epoch 74/700\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.5951 - precision_6: 0.6617 - recall_6: 0.5196\n",
            "Epoch 75/700\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5943 - precision_6: 0.6619 - recall_6: 0.5228\n",
            "Epoch 76/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5936 - precision_6: 0.6622 - recall_6: 0.5288\n",
            "Epoch 77/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5929 - precision_6: 0.6631 - recall_6: 0.5298\n",
            "Epoch 78/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5922 - precision_6: 0.6632 - recall_6: 0.5312\n",
            "Epoch 79/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5914 - precision_6: 0.6631 - recall_6: 0.5280\n",
            "Epoch 80/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5907 - precision_6: 0.6641 - recall_6: 0.5306\n",
            "Epoch 81/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5901 - precision_6: 0.6660 - recall_6: 0.5348\n",
            "Epoch 82/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5894 - precision_6: 0.6667 - recall_6: 0.5338\n",
            "Epoch 83/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5887 - precision_6: 0.6682 - recall_6: 0.5344\n",
            "Epoch 84/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5881 - precision_6: 0.6691 - recall_6: 0.5390\n",
            "Epoch 85/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5874 - precision_6: 0.6701 - recall_6: 0.5378\n",
            "Epoch 86/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5867 - precision_6: 0.6706 - recall_6: 0.5326\n",
            "Epoch 87/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5861 - precision_6: 0.6732 - recall_6: 0.5302\n",
            "Epoch 88/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5854 - precision_6: 0.6734 - recall_6: 0.5364\n",
            "Epoch 89/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5847 - precision_6: 0.6738 - recall_6: 0.5288\n",
            "Epoch 90/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5841 - precision_6: 0.6744 - recall_6: 0.5378\n",
            "Epoch 91/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5835 - precision_6: 0.6741 - recall_6: 0.5416\n",
            "Epoch 92/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5829 - precision_6: 0.6740 - recall_6: 0.5430\n",
            "Epoch 93/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5822 - precision_6: 0.6742 - recall_6: 0.5458\n",
            "Epoch 94/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5816 - precision_6: 0.6753 - recall_6: 0.5444\n",
            "Epoch 95/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5810 - precision_6: 0.6772 - recall_6: 0.5420\n",
            "Epoch 96/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5804 - precision_6: 0.6751 - recall_6: 0.5452\n",
            "Epoch 97/700\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5798 - precision_6: 0.6753 - recall_6: 0.5458\n",
            "Epoch 98/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5792 - precision_6: 0.6766 - recall_6: 0.5418\n",
            "Epoch 99/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5786 - precision_6: 0.6767 - recall_6: 0.5408\n",
            "Epoch 100/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5781 - precision_6: 0.6782 - recall_6: 0.5404\n",
            "Epoch 101/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5775 - precision_6: 0.6771 - recall_6: 0.5468\n",
            "Epoch 102/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5769 - precision_6: 0.6798 - recall_6: 0.5430\n",
            "Epoch 103/700\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.5763 - precision_6: 0.6795 - recall_6: 0.5440\n",
            "Epoch 104/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.5758 - precision_6: 0.6780 - recall_6: 0.5454\n",
            "Epoch 105/700\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5752 - precision_6: 0.6799 - recall_6: 0.5454\n",
            "Epoch 106/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5746 - precision_6: 0.6790 - recall_6: 0.5508\n",
            "Epoch 107/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.5741 - precision_6: 0.6790 - recall_6: 0.5486\n",
            "Epoch 108/700\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5735 - precision_6: 0.6809 - recall_6: 0.5492\n",
            "Epoch 109/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5730 - precision_6: 0.6821 - recall_6: 0.5464\n",
            "Epoch 110/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5725 - precision_6: 0.6859 - recall_6: 0.5438\n",
            "Epoch 111/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5720 - precision_6: 0.6888 - recall_6: 0.5422\n",
            "Epoch 112/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5714 - precision_6: 0.6856 - recall_6: 0.5456\n",
            "Epoch 113/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5708 - precision_6: 0.6848 - recall_6: 0.5496\n",
            "Epoch 114/700\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5703 - precision_6: 0.6845 - recall_6: 0.5532\n",
            "Epoch 115/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5698 - precision_6: 0.6838 - recall_6: 0.5546\n",
            "Epoch 116/700\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5693 - precision_6: 0.6815 - recall_6: 0.5572\n",
            "Epoch 117/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5688 - precision_6: 0.6815 - recall_6: 0.5588\n",
            "Epoch 118/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5682 - precision_6: 0.6824 - recall_6: 0.5590\n",
            "Epoch 119/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5677 - precision_6: 0.6830 - recall_6: 0.5594\n",
            "Epoch 120/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5672 - precision_6: 0.6854 - recall_6: 0.5572\n",
            "Epoch 121/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5667 - precision_6: 0.6893 - recall_6: 0.5552\n",
            "Epoch 122/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5662 - precision_6: 0.6899 - recall_6: 0.5566\n",
            "Epoch 123/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5656 - precision_6: 0.6877 - recall_6: 0.5580\n",
            "Epoch 124/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5652 - precision_6: 0.6868 - recall_6: 0.5610\n",
            "Epoch 125/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5647 - precision_6: 0.6868 - recall_6: 0.5650\n",
            "Epoch 126/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5642 - precision_6: 0.6880 - recall_6: 0.5644\n",
            "Epoch 127/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5637 - precision_6: 0.6893 - recall_6: 0.5648\n",
            "Epoch 128/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5632 - precision_6: 0.6901 - recall_6: 0.5634\n",
            "Epoch 129/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5627 - precision_6: 0.6911 - recall_6: 0.5674\n",
            "Epoch 130/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5622 - precision_6: 0.6909 - recall_6: 0.5692\n",
            "Epoch 131/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5618 - precision_6: 0.6916 - recall_6: 0.5678\n",
            "Epoch 132/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5613 - precision_6: 0.6924 - recall_6: 0.5660\n",
            "Epoch 133/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5608 - precision_6: 0.6917 - recall_6: 0.5690\n",
            "Epoch 134/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5603 - precision_6: 0.6927 - recall_6: 0.5690\n",
            "Epoch 135/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5599 - precision_6: 0.6929 - recall_6: 0.5696\n",
            "Epoch 136/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5594 - precision_6: 0.6896 - recall_6: 0.5776\n",
            "Epoch 137/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5590 - precision_6: 0.6892 - recall_6: 0.5784\n",
            "Epoch 138/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5585 - precision_6: 0.6893 - recall_6: 0.5796\n",
            "Epoch 139/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5580 - precision_6: 0.6914 - recall_6: 0.5768\n",
            "Epoch 140/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5576 - precision_6: 0.6917 - recall_6: 0.5756\n",
            "Epoch 141/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5571 - precision_6: 0.6931 - recall_6: 0.5750\n",
            "Epoch 142/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5567 - precision_6: 0.6944 - recall_6: 0.5722\n",
            "Epoch 143/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5562 - precision_6: 0.6945 - recall_6: 0.5732\n",
            "Epoch 144/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5558 - precision_6: 0.6941 - recall_6: 0.5760\n",
            "Epoch 145/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5553 - precision_6: 0.6957 - recall_6: 0.5748\n",
            "Epoch 146/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5549 - precision_6: 0.6962 - recall_6: 0.5780\n",
            "Epoch 147/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5545 - precision_6: 0.6963 - recall_6: 0.5768\n",
            "Epoch 148/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5540 - precision_6: 0.6978 - recall_6: 0.5750\n",
            "Epoch 149/700\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5536 - precision_6: 0.6971 - recall_6: 0.5768\n",
            "Epoch 150/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5532 - precision_6: 0.6964 - recall_6: 0.5802\n",
            "Epoch 151/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.5527 - precision_6: 0.6970 - recall_6: 0.5798\n",
            "Epoch 152/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.5523 - precision_6: 0.6967 - recall_6: 0.5820\n",
            "Epoch 153/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5519 - precision_6: 0.6972 - recall_6: 0.5794\n",
            "Epoch 154/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.5515 - precision_6: 0.6982 - recall_6: 0.5834\n",
            "Epoch 155/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.5510 - precision_6: 0.6983 - recall_6: 0.5818\n",
            "Epoch 156/700\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5506 - precision_6: 0.6983 - recall_6: 0.5772\n",
            "Epoch 157/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.5502 - precision_6: 0.6982 - recall_6: 0.5788\n",
            "Epoch 158/700\n",
            "2/2 [==============================] - 1s 126ms/step - loss: 0.5498 - precision_6: 0.7002 - recall_6: 0.5774\n",
            "Epoch 159/700\n",
            "2/2 [==============================] - 1s 115ms/step - loss: 0.5494 - precision_6: 0.7014 - recall_6: 0.5782\n",
            "Epoch 160/700\n",
            "2/2 [==============================] - 1s 137ms/step - loss: 0.5490 - precision_6: 0.7003 - recall_6: 0.5838\n",
            "Epoch 161/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5485 - precision_6: 0.7018 - recall_6: 0.5850\n",
            "Epoch 162/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5482 - precision_6: 0.7018 - recall_6: 0.5856\n",
            "Epoch 163/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5478 - precision_6: 0.7001 - recall_6: 0.5940\n",
            "Epoch 164/700\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5474 - precision_6: 0.7002 - recall_6: 0.5946\n",
            "Epoch 165/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.5470 - precision_6: 0.7002 - recall_6: 0.5960\n",
            "Epoch 166/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5465 - precision_6: 0.7028 - recall_6: 0.5926\n",
            "Epoch 167/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5461 - precision_6: 0.7020 - recall_6: 0.5936\n",
            "Epoch 168/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5458 - precision_6: 0.7042 - recall_6: 0.5852\n",
            "Epoch 169/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5454 - precision_6: 0.7044 - recall_6: 0.5890\n",
            "Epoch 170/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5450 - precision_6: 0.7043 - recall_6: 0.5884\n",
            "Epoch 171/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5446 - precision_6: 0.7044 - recall_6: 0.5886\n",
            "Epoch 172/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5442 - precision_6: 0.7076 - recall_6: 0.5848\n",
            "Epoch 173/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5438 - precision_6: 0.7047 - recall_6: 0.5904\n",
            "Epoch 174/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5435 - precision_6: 0.7063 - recall_6: 0.5876\n",
            "Epoch 175/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5431 - precision_6: 0.7070 - recall_6: 0.5860\n",
            "Epoch 176/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5427 - precision_6: 0.7065 - recall_6: 0.5860\n",
            "Epoch 177/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5423 - precision_6: 0.7082 - recall_6: 0.5838\n",
            "Epoch 178/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5419 - precision_6: 0.7069 - recall_6: 0.5884\n",
            "Epoch 179/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5416 - precision_6: 0.7070 - recall_6: 0.5872\n",
            "Epoch 180/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5412 - precision_6: 0.7082 - recall_6: 0.5868\n",
            "Epoch 181/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5408 - precision_6: 0.7065 - recall_6: 0.5888\n",
            "Epoch 182/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5405 - precision_6: 0.7068 - recall_6: 0.5902\n",
            "Epoch 183/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5401 - precision_6: 0.7064 - recall_6: 0.5920\n",
            "Epoch 184/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5397 - precision_6: 0.7071 - recall_6: 0.5916\n",
            "Epoch 185/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5394 - precision_6: 0.7071 - recall_6: 0.5940\n",
            "Epoch 186/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5390 - precision_6: 0.7075 - recall_6: 0.5932\n",
            "Epoch 187/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5387 - precision_6: 0.7077 - recall_6: 0.5938\n",
            "Epoch 188/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5383 - precision_6: 0.7075 - recall_6: 0.5942\n",
            "Epoch 189/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5380 - precision_6: 0.7085 - recall_6: 0.5930\n",
            "Epoch 190/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5377 - precision_6: 0.7098 - recall_6: 0.5920\n",
            "Epoch 191/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5373 - precision_6: 0.7112 - recall_6: 0.5916\n",
            "Epoch 192/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5370 - precision_6: 0.7111 - recall_6: 0.5922\n",
            "Epoch 193/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5366 - precision_6: 0.7103 - recall_6: 0.5948\n",
            "Epoch 194/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5363 - precision_6: 0.7126 - recall_6: 0.5930\n",
            "Epoch 195/700\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.5359 - precision_6: 0.7129 - recall_6: 0.5940\n",
            "Epoch 196/700\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.5356 - precision_6: 0.7131 - recall_6: 0.5930\n",
            "Epoch 197/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.5353 - precision_6: 0.7127 - recall_6: 0.5948\n",
            "Epoch 198/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.5349 - precision_6: 0.7130 - recall_6: 0.5972\n",
            "Epoch 199/700\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.5346 - precision_6: 0.7133 - recall_6: 0.5956\n",
            "Epoch 200/700\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.5342 - precision_6: 0.7130 - recall_6: 0.5972\n",
            "Epoch 201/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.5339 - precision_6: 0.7120 - recall_6: 0.5982\n",
            "Epoch 202/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5336 - precision_6: 0.7112 - recall_6: 0.5990\n",
            "Epoch 203/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5333 - precision_6: 0.7114 - recall_6: 0.6038\n",
            "Epoch 204/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5329 - precision_6: 0.7123 - recall_6: 0.5982\n",
            "Epoch 205/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5326 - precision_6: 0.7143 - recall_6: 0.5960\n",
            "Epoch 206/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5322 - precision_6: 0.7139 - recall_6: 0.5990\n",
            "Epoch 207/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5319 - precision_6: 0.7133 - recall_6: 0.6000\n",
            "Epoch 208/700\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5316 - precision_6: 0.7162 - recall_6: 0.5970\n",
            "Epoch 209/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5313 - precision_6: 0.7162 - recall_6: 0.5976\n",
            "Epoch 210/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5309 - precision_6: 0.7148 - recall_6: 0.5980\n",
            "Epoch 211/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5306 - precision_6: 0.7151 - recall_6: 0.5980\n",
            "Epoch 212/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5303 - precision_6: 0.7168 - recall_6: 0.5962\n",
            "Epoch 213/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5300 - precision_6: 0.7198 - recall_6: 0.5950\n",
            "Epoch 214/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5297 - precision_6: 0.7171 - recall_6: 0.5962\n",
            "Epoch 215/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5294 - precision_6: 0.7176 - recall_6: 0.5962\n",
            "Epoch 216/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5291 - precision_6: 0.7190 - recall_6: 0.5952\n",
            "Epoch 217/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5287 - precision_6: 0.7196 - recall_6: 0.5960\n",
            "Epoch 218/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5284 - precision_6: 0.7174 - recall_6: 0.5996\n",
            "Epoch 219/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5281 - precision_6: 0.7177 - recall_6: 0.6016\n",
            "Epoch 220/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5278 - precision_6: 0.7171 - recall_6: 0.6052\n",
            "Epoch 221/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5275 - precision_6: 0.7167 - recall_6: 0.6036\n",
            "Epoch 222/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5272 - precision_6: 0.7164 - recall_6: 0.6046\n",
            "Epoch 223/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5269 - precision_6: 0.7185 - recall_6: 0.6024\n",
            "Epoch 224/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5266 - precision_6: 0.7200 - recall_6: 0.6034\n",
            "Epoch 225/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5263 - precision_6: 0.7214 - recall_6: 0.6002\n",
            "Epoch 226/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5261 - precision_6: 0.7227 - recall_6: 0.5998\n",
            "Epoch 227/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5258 - precision_6: 0.7226 - recall_6: 0.5960\n",
            "Epoch 228/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5255 - precision_6: 0.7233 - recall_6: 0.5982\n",
            "Epoch 229/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5252 - precision_6: 0.7233 - recall_6: 0.6002\n",
            "Epoch 230/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5249 - precision_6: 0.7233 - recall_6: 0.6022\n",
            "Epoch 231/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5246 - precision_6: 0.7217 - recall_6: 0.6042\n",
            "Epoch 232/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5243 - precision_6: 0.7218 - recall_6: 0.6050\n",
            "Epoch 233/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5240 - precision_6: 0.7231 - recall_6: 0.6032\n",
            "Epoch 234/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5237 - precision_6: 0.7229 - recall_6: 0.6042\n",
            "Epoch 235/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5234 - precision_6: 0.7216 - recall_6: 0.6056\n",
            "Epoch 236/700\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.5231 - precision_6: 0.7210 - recall_6: 0.6084\n",
            "Epoch 237/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5229 - precision_6: 0.7201 - recall_6: 0.6114\n",
            "Epoch 238/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.5226 - precision_6: 0.7208 - recall_6: 0.6150\n",
            "Epoch 239/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5223 - precision_6: 0.7215 - recall_6: 0.6104\n",
            "Epoch 240/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5220 - precision_6: 0.7224 - recall_6: 0.6120\n",
            "Epoch 241/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5217 - precision_6: 0.7235 - recall_6: 0.6106\n",
            "Epoch 242/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5214 - precision_6: 0.7250 - recall_6: 0.6090\n",
            "Epoch 243/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5212 - precision_6: 0.7241 - recall_6: 0.6132\n",
            "Epoch 244/700\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.5209 - precision_6: 0.7242 - recall_6: 0.6164\n",
            "Epoch 245/700\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.5206 - precision_6: 0.7245 - recall_6: 0.6158\n",
            "Epoch 246/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5203 - precision_6: 0.7261 - recall_6: 0.6156\n",
            "Epoch 247/700\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.5201 - precision_6: 0.7258 - recall_6: 0.6166\n",
            "Epoch 248/700\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5198 - precision_6: 0.7261 - recall_6: 0.6140\n",
            "Epoch 249/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.5195 - precision_6: 0.7272 - recall_6: 0.6136\n",
            "Epoch 250/700\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.5193 - precision_6: 0.7261 - recall_6: 0.6178\n",
            "Epoch 251/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5190 - precision_6: 0.7276 - recall_6: 0.6160\n",
            "Epoch 252/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5187 - precision_6: 0.7274 - recall_6: 0.6168\n",
            "Epoch 253/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5184 - precision_6: 0.7279 - recall_6: 0.6178\n",
            "Epoch 254/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5182 - precision_6: 0.7281 - recall_6: 0.6180\n",
            "Epoch 255/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5179 - precision_6: 0.7272 - recall_6: 0.6178\n",
            "Epoch 256/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5177 - precision_6: 0.7289 - recall_6: 0.6172\n",
            "Epoch 257/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5174 - precision_6: 0.7285 - recall_6: 0.6182\n",
            "Epoch 258/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5171 - precision_6: 0.7300 - recall_6: 0.6176\n",
            "Epoch 259/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5169 - precision_6: 0.7297 - recall_6: 0.6210\n",
            "Epoch 260/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5166 - precision_6: 0.7288 - recall_6: 0.6228\n",
            "Epoch 261/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5164 - precision_6: 0.7293 - recall_6: 0.6218\n",
            "Epoch 262/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5161 - precision_6: 0.7296 - recall_6: 0.6228\n",
            "Epoch 263/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5159 - precision_6: 0.7276 - recall_6: 0.6298\n",
            "Epoch 264/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5156 - precision_6: 0.7288 - recall_6: 0.6304\n",
            "Epoch 265/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5154 - precision_6: 0.7273 - recall_6: 0.6314\n",
            "Epoch 266/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5151 - precision_6: 0.7278 - recall_6: 0.6330\n",
            "Epoch 267/700\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.5149 - precision_6: 0.7288 - recall_6: 0.6320\n",
            "Epoch 268/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5146 - precision_6: 0.7322 - recall_6: 0.6268\n",
            "Epoch 269/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5143 - precision_6: 0.7323 - recall_6: 0.6276\n",
            "Epoch 270/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.5141 - precision_6: 0.7327 - recall_6: 0.6262\n",
            "Epoch 271/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5138 - precision_6: 0.7347 - recall_6: 0.6204\n",
            "Epoch 272/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5136 - precision_6: 0.7340 - recall_6: 0.6236\n",
            "Epoch 273/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5133 - precision_6: 0.7341 - recall_6: 0.6282\n",
            "Epoch 274/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5131 - precision_6: 0.7324 - recall_6: 0.6296\n",
            "Epoch 275/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5128 - precision_6: 0.7343 - recall_6: 0.6286\n",
            "Epoch 276/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5126 - precision_6: 0.7348 - recall_6: 0.6268\n",
            "Epoch 277/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5123 - precision_6: 0.7337 - recall_6: 0.6288\n",
            "Epoch 278/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5121 - precision_6: 0.7353 - recall_6: 0.6268\n",
            "Epoch 279/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5119 - precision_6: 0.7333 - recall_6: 0.6292\n",
            "Epoch 280/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5116 - precision_6: 0.7353 - recall_6: 0.6266\n",
            "Epoch 281/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5114 - precision_6: 0.7344 - recall_6: 0.6260\n",
            "Epoch 282/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5111 - precision_6: 0.7341 - recall_6: 0.6288\n",
            "Epoch 283/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5109 - precision_6: 0.7336 - recall_6: 0.6310\n",
            "Epoch 284/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5107 - precision_6: 0.7335 - recall_6: 0.6304\n",
            "Epoch 285/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5104 - precision_6: 0.7340 - recall_6: 0.6304\n",
            "Epoch 286/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5102 - precision_6: 0.7345 - recall_6: 0.6324\n",
            "Epoch 287/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5100 - precision_6: 0.7372 - recall_6: 0.6282\n",
            "Epoch 288/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5097 - precision_6: 0.7376 - recall_6: 0.6256\n",
            "Epoch 289/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5095 - precision_6: 0.7371 - recall_6: 0.6292\n",
            "Epoch 290/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.5093 - precision_6: 0.7379 - recall_6: 0.6262\n",
            "Epoch 291/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5091 - precision_6: 0.7387 - recall_6: 0.6264\n",
            "Epoch 292/700\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.5088 - precision_6: 0.7396 - recall_6: 0.6248\n",
            "Epoch 293/700\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.5086 - precision_6: 0.7389 - recall_6: 0.6276\n",
            "Epoch 294/700\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.5084 - precision_6: 0.7386 - recall_6: 0.6262\n",
            "Epoch 295/700\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.5081 - precision_6: 0.7361 - recall_6: 0.6294\n",
            "Epoch 296/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5079 - precision_6: 0.7363 - recall_6: 0.6298\n",
            "Epoch 297/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.5077 - precision_6: 0.7360 - recall_6: 0.6318\n",
            "Epoch 298/700\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.5075 - precision_6: 0.7365 - recall_6: 0.6318\n",
            "Epoch 299/700\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.5072 - precision_6: 0.7367 - recall_6: 0.6318\n",
            "Epoch 300/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.5070 - precision_6: 0.7375 - recall_6: 0.6306\n",
            "Epoch 301/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5068 - precision_6: 0.7377 - recall_6: 0.6322\n",
            "Epoch 302/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5066 - precision_6: 0.7384 - recall_6: 0.6310\n",
            "Epoch 303/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5064 - precision_6: 0.7387 - recall_6: 0.6326\n",
            "Epoch 304/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5062 - precision_6: 0.7388 - recall_6: 0.6312\n",
            "Epoch 305/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5059 - precision_6: 0.7381 - recall_6: 0.6342\n",
            "Epoch 306/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5057 - precision_6: 0.7383 - recall_6: 0.6336\n",
            "Epoch 307/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5055 - precision_6: 0.7391 - recall_6: 0.6324\n",
            "Epoch 308/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5053 - precision_6: 0.7388 - recall_6: 0.6320\n",
            "Epoch 309/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5051 - precision_6: 0.7391 - recall_6: 0.6306\n",
            "Epoch 310/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5048 - precision_6: 0.7392 - recall_6: 0.6310\n",
            "Epoch 311/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5046 - precision_6: 0.7377 - recall_6: 0.6338\n",
            "Epoch 312/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5044 - precision_6: 0.7376 - recall_6: 0.6340\n",
            "Epoch 313/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5042 - precision_6: 0.7381 - recall_6: 0.6330\n",
            "Epoch 314/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.5040 - precision_6: 0.7371 - recall_6: 0.6352\n",
            "Epoch 315/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.5038 - precision_6: 0.7372 - recall_6: 0.6344\n",
            "Epoch 316/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.5036 - precision_6: 0.7375 - recall_6: 0.6354\n",
            "Epoch 317/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5034 - precision_6: 0.7384 - recall_6: 0.6396\n",
            "Epoch 318/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.5032 - precision_6: 0.7387 - recall_6: 0.6406\n",
            "Epoch 319/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.5030 - precision_6: 0.7386 - recall_6: 0.6418\n",
            "Epoch 320/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5027 - precision_6: 0.7385 - recall_6: 0.6378\n",
            "Epoch 321/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5025 - precision_6: 0.7387 - recall_6: 0.6366\n",
            "Epoch 322/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5023 - precision_6: 0.7385 - recall_6: 0.6410\n",
            "Epoch 323/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5021 - precision_6: 0.7386 - recall_6: 0.6376\n",
            "Epoch 324/700\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5019 - precision_6: 0.7385 - recall_6: 0.6412\n",
            "Epoch 325/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.5017 - precision_6: 0.7384 - recall_6: 0.6384\n",
            "Epoch 326/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5015 - precision_6: 0.7379 - recall_6: 0.6390\n",
            "Epoch 327/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5013 - precision_6: 0.7383 - recall_6: 0.6416\n",
            "Epoch 328/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5011 - precision_6: 0.7383 - recall_6: 0.6380\n",
            "Epoch 329/700\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5009 - precision_6: 0.7386 - recall_6: 0.6362\n",
            "Epoch 330/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5007 - precision_6: 0.7391 - recall_6: 0.6386\n",
            "Epoch 331/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5005 - precision_6: 0.7388 - recall_6: 0.6422\n",
            "Epoch 332/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.5003 - precision_6: 0.7394 - recall_6: 0.6418\n",
            "Epoch 333/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.5001 - precision_6: 0.7392 - recall_6: 0.6416\n",
            "Epoch 334/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4999 - precision_6: 0.7382 - recall_6: 0.6450\n",
            "Epoch 335/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4997 - precision_6: 0.7397 - recall_6: 0.6432\n",
            "Epoch 336/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4995 - precision_6: 0.7404 - recall_6: 0.6424\n",
            "Epoch 337/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4993 - precision_6: 0.7408 - recall_6: 0.6430\n",
            "Epoch 338/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4991 - precision_6: 0.7404 - recall_6: 0.6428\n",
            "Epoch 339/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4989 - precision_6: 0.7415 - recall_6: 0.6392\n",
            "Epoch 340/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4987 - precision_6: 0.7412 - recall_6: 0.6416\n",
            "Epoch 341/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.4985 - precision_6: 0.7420 - recall_6: 0.6396\n",
            "Epoch 342/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.4983 - precision_6: 0.7423 - recall_6: 0.6394\n",
            "Epoch 343/700\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.4981 - precision_6: 0.7421 - recall_6: 0.6394\n",
            "Epoch 344/700\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.4979 - precision_6: 0.7422 - recall_6: 0.6402\n",
            "Epoch 345/700\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.4977 - precision_6: 0.7414 - recall_6: 0.6428\n",
            "Epoch 346/700\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.4975 - precision_6: 0.7414 - recall_6: 0.6422\n",
            "Epoch 347/700\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.4973 - precision_6: 0.7416 - recall_6: 0.6418\n",
            "Epoch 348/700\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.4971 - precision_6: 0.7415 - recall_6: 0.6430\n",
            "Epoch 349/700\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.4969 - precision_6: 0.7419 - recall_6: 0.6422\n",
            "Epoch 350/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4967 - precision_6: 0.7425 - recall_6: 0.6414\n",
            "Epoch 351/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4966 - precision_6: 0.7427 - recall_6: 0.6408\n",
            "Epoch 352/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4964 - precision_6: 0.7425 - recall_6: 0.6420\n",
            "Epoch 353/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4962 - precision_6: 0.7423 - recall_6: 0.6402\n",
            "Epoch 354/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4960 - precision_6: 0.7420 - recall_6: 0.6432\n",
            "Epoch 355/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4958 - precision_6: 0.7421 - recall_6: 0.6422\n",
            "Epoch 356/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4956 - precision_6: 0.7425 - recall_6: 0.6424\n",
            "Epoch 357/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4955 - precision_6: 0.7420 - recall_6: 0.6420\n",
            "Epoch 358/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4953 - precision_6: 0.7421 - recall_6: 0.6412\n",
            "Epoch 359/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4951 - precision_6: 0.7421 - recall_6: 0.6412\n",
            "Epoch 360/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4949 - precision_6: 0.7417 - recall_6: 0.6428\n",
            "Epoch 361/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4947 - precision_6: 0.7423 - recall_6: 0.6394\n",
            "Epoch 362/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4945 - precision_6: 0.7422 - recall_6: 0.6398\n",
            "Epoch 363/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4944 - precision_6: 0.7435 - recall_6: 0.6382\n",
            "Epoch 364/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4942 - precision_6: 0.7434 - recall_6: 0.6390\n",
            "Epoch 365/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4940 - precision_6: 0.7432 - recall_6: 0.6396\n",
            "Epoch 366/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4938 - precision_6: 0.7423 - recall_6: 0.6424\n",
            "Epoch 367/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4936 - precision_6: 0.7450 - recall_6: 0.6392\n",
            "Epoch 368/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4934 - precision_6: 0.7434 - recall_6: 0.6402\n",
            "Epoch 369/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4933 - precision_6: 0.7425 - recall_6: 0.6424\n",
            "Epoch 370/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4931 - precision_6: 0.7430 - recall_6: 0.6412\n",
            "Epoch 371/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4929 - precision_6: 0.7448 - recall_6: 0.6398\n",
            "Epoch 372/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4927 - precision_6: 0.7437 - recall_6: 0.6402\n",
            "Epoch 373/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4925 - precision_6: 0.7429 - recall_6: 0.6426\n",
            "Epoch 374/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4924 - precision_6: 0.7436 - recall_6: 0.6410\n",
            "Epoch 375/700\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4922 - precision_6: 0.7440 - recall_6: 0.6410\n",
            "Epoch 376/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4920 - precision_6: 0.7478 - recall_6: 0.6388\n",
            "Epoch 377/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4918 - precision_6: 0.7471 - recall_6: 0.6394\n",
            "Epoch 378/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4916 - precision_6: 0.7465 - recall_6: 0.6396\n",
            "Epoch 379/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4915 - precision_6: 0.7442 - recall_6: 0.6406\n",
            "Epoch 380/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4913 - precision_6: 0.7460 - recall_6: 0.6398\n",
            "Epoch 381/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4911 - precision_6: 0.7462 - recall_6: 0.6398\n",
            "Epoch 382/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4909 - precision_6: 0.7462 - recall_6: 0.6416\n",
            "Epoch 383/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4907 - precision_6: 0.7458 - recall_6: 0.6412\n",
            "Epoch 384/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4906 - precision_6: 0.7456 - recall_6: 0.6402\n",
            "Epoch 385/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4904 - precision_6: 0.7445 - recall_6: 0.6412\n",
            "Epoch 386/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4902 - precision_6: 0.7448 - recall_6: 0.6404\n",
            "Epoch 387/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4900 - precision_6: 0.7451 - recall_6: 0.6406\n",
            "Epoch 388/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4899 - precision_6: 0.7448 - recall_6: 0.6426\n",
            "Epoch 389/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4897 - precision_6: 0.7450 - recall_6: 0.6438\n",
            "Epoch 390/700\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.4896 - precision_6: 0.7449 - recall_6: 0.6454\n",
            "Epoch 391/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.4894 - precision_6: 0.7453 - recall_6: 0.6474\n",
            "Epoch 392/700\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.4892 - precision_6: 0.7467 - recall_6: 0.6438\n",
            "Epoch 393/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.4890 - precision_6: 0.7480 - recall_6: 0.6442\n",
            "Epoch 394/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.4889 - precision_6: 0.7476 - recall_6: 0.6450\n",
            "Epoch 395/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.4887 - precision_6: 0.7470 - recall_6: 0.6460\n",
            "Epoch 396/700\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4886 - precision_6: 0.7488 - recall_6: 0.6450\n",
            "Epoch 397/700\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.4884 - precision_6: 0.7474 - recall_6: 0.6462\n",
            "Epoch 398/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4882 - precision_6: 0.7489 - recall_6: 0.6460\n",
            "Epoch 399/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4880 - precision_6: 0.7485 - recall_6: 0.6470\n",
            "Epoch 400/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4879 - precision_6: 0.7465 - recall_6: 0.6502\n",
            "Epoch 401/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4877 - precision_6: 0.7478 - recall_6: 0.6488\n",
            "Epoch 402/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4875 - precision_6: 0.7478 - recall_6: 0.6510\n",
            "Epoch 403/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4874 - precision_6: 0.7492 - recall_6: 0.6478\n",
            "Epoch 404/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4872 - precision_6: 0.7502 - recall_6: 0.6470\n",
            "Epoch 405/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4870 - precision_6: 0.7489 - recall_6: 0.6490\n",
            "Epoch 406/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4869 - precision_6: 0.7474 - recall_6: 0.6502\n",
            "Epoch 407/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4867 - precision_6: 0.7470 - recall_6: 0.6512\n",
            "Epoch 408/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4866 - precision_6: 0.7482 - recall_6: 0.6502\n",
            "Epoch 409/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4864 - precision_6: 0.7509 - recall_6: 0.6470\n",
            "Epoch 410/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4862 - precision_6: 0.7517 - recall_6: 0.6478\n",
            "Epoch 411/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4861 - precision_6: 0.7510 - recall_6: 0.6484\n",
            "Epoch 412/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4859 - precision_6: 0.7501 - recall_6: 0.6490\n",
            "Epoch 413/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4857 - precision_6: 0.7498 - recall_6: 0.6492\n",
            "Epoch 414/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4856 - precision_6: 0.7514 - recall_6: 0.6482\n",
            "Epoch 415/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4854 - precision_6: 0.7526 - recall_6: 0.6456\n",
            "Epoch 416/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4853 - precision_6: 0.7499 - recall_6: 0.6488\n",
            "Epoch 417/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4851 - precision_6: 0.7484 - recall_6: 0.6504\n",
            "Epoch 418/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4849 - precision_6: 0.7490 - recall_6: 0.6504\n",
            "Epoch 419/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4848 - precision_6: 0.7481 - recall_6: 0.6528\n",
            "Epoch 420/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4846 - precision_6: 0.7509 - recall_6: 0.6482\n",
            "Epoch 421/700\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.4844 - precision_6: 0.7508 - recall_6: 0.6484\n",
            "Epoch 422/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4843 - precision_6: 0.7529 - recall_6: 0.6460\n",
            "Epoch 423/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4841 - precision_6: 0.7528 - recall_6: 0.6468\n",
            "Epoch 424/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4840 - precision_6: 0.7523 - recall_6: 0.6476\n",
            "Epoch 425/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4838 - precision_6: 0.7517 - recall_6: 0.6484\n",
            "Epoch 426/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4836 - precision_6: 0.7516 - recall_6: 0.6500\n",
            "Epoch 427/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4835 - precision_6: 0.7527 - recall_6: 0.6494\n",
            "Epoch 428/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4833 - precision_6: 0.7539 - recall_6: 0.6476\n",
            "Epoch 429/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4832 - precision_6: 0.7528 - recall_6: 0.6480\n",
            "Epoch 430/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4830 - precision_6: 0.7517 - recall_6: 0.6492\n",
            "Epoch 431/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4829 - precision_6: 0.7520 - recall_6: 0.6502\n",
            "Epoch 432/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4827 - precision_6: 0.7487 - recall_6: 0.6532\n",
            "Epoch 433/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4826 - precision_6: 0.7493 - recall_6: 0.6514\n",
            "Epoch 434/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4824 - precision_6: 0.7497 - recall_6: 0.6512\n",
            "Epoch 435/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4822 - precision_6: 0.7496 - recall_6: 0.6514\n",
            "Epoch 436/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4821 - precision_6: 0.7514 - recall_6: 0.6500\n",
            "Epoch 437/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4819 - precision_6: 0.7505 - recall_6: 0.6502\n",
            "Epoch 438/700\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.4818 - precision_6: 0.7513 - recall_6: 0.6496\n",
            "Epoch 439/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.4816 - precision_6: 0.7498 - recall_6: 0.6514\n",
            "Epoch 440/700\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4815 - precision_6: 0.7507 - recall_6: 0.6504\n",
            "Epoch 441/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.4813 - precision_6: 0.7509 - recall_6: 0.6500\n",
            "Epoch 442/700\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.4812 - precision_6: 0.7512 - recall_6: 0.6496\n",
            "Epoch 443/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.4810 - precision_6: 0.7502 - recall_6: 0.6510\n",
            "Epoch 444/700\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.4809 - precision_6: 0.7504 - recall_6: 0.6512\n",
            "Epoch 445/700\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.4807 - precision_6: 0.7517 - recall_6: 0.6486\n",
            "Epoch 446/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4805 - precision_6: 0.7519 - recall_6: 0.6498\n",
            "Epoch 447/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4804 - precision_6: 0.7513 - recall_6: 0.6500\n",
            "Epoch 448/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4802 - precision_6: 0.7517 - recall_6: 0.6492\n",
            "Epoch 449/700\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4801 - precision_6: 0.7515 - recall_6: 0.6484\n",
            "Epoch 450/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4799 - precision_6: 0.7522 - recall_6: 0.6484\n",
            "Epoch 451/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4798 - precision_6: 0.7506 - recall_6: 0.6524\n",
            "Epoch 452/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4796 - precision_6: 0.7524 - recall_6: 0.6486\n",
            "Epoch 453/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4795 - precision_6: 0.7526 - recall_6: 0.6480\n",
            "Epoch 454/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4793 - precision_6: 0.7509 - recall_6: 0.6528\n",
            "Epoch 455/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4792 - precision_6: 0.7516 - recall_6: 0.6498\n",
            "Epoch 456/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4790 - precision_6: 0.7529 - recall_6: 0.6484\n",
            "Epoch 457/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4789 - precision_6: 0.7540 - recall_6: 0.6466\n",
            "Epoch 458/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4787 - precision_6: 0.7525 - recall_6: 0.6512\n",
            "Epoch 459/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4786 - precision_6: 0.7544 - recall_6: 0.6470\n",
            "Epoch 460/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4784 - precision_6: 0.7542 - recall_6: 0.6480\n",
            "Epoch 461/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4783 - precision_6: 0.7543 - recall_6: 0.6502\n",
            "Epoch 462/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4781 - precision_6: 0.7546 - recall_6: 0.6496\n",
            "Epoch 463/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4780 - precision_6: 0.7550 - recall_6: 0.6472\n",
            "Epoch 464/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4778 - precision_6: 0.7544 - recall_6: 0.6506\n",
            "Epoch 465/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4777 - precision_6: 0.7545 - recall_6: 0.6520\n",
            "Epoch 466/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4775 - precision_6: 0.7543 - recall_6: 0.6516\n",
            "Epoch 467/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4774 - precision_6: 0.7546 - recall_6: 0.6508\n",
            "Epoch 468/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4772 - precision_6: 0.7540 - recall_6: 0.6540\n",
            "Epoch 469/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4771 - precision_6: 0.7546 - recall_6: 0.6518\n",
            "Epoch 470/700\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.4769 - precision_6: 0.7547 - recall_6: 0.6528\n",
            "Epoch 471/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4768 - precision_6: 0.7558 - recall_6: 0.6518\n",
            "Epoch 472/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4766 - precision_6: 0.7558 - recall_6: 0.6494\n",
            "Epoch 473/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4765 - precision_6: 0.7557 - recall_6: 0.6484\n",
            "Epoch 474/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4763 - precision_6: 0.7560 - recall_6: 0.6500\n",
            "Epoch 475/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4762 - precision_6: 0.7559 - recall_6: 0.6490\n",
            "Epoch 476/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4761 - precision_6: 0.7558 - recall_6: 0.6488\n",
            "Epoch 477/700\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.4759 - precision_6: 0.7561 - recall_6: 0.6522\n",
            "Epoch 478/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.4758 - precision_6: 0.7560 - recall_6: 0.6524\n",
            "Epoch 479/700\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.4756 - precision_6: 0.7562 - recall_6: 0.6506\n",
            "Epoch 480/700\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.4755 - precision_6: 0.7570 - recall_6: 0.6492\n",
            "Epoch 481/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.4753 - precision_6: 0.7563 - recall_6: 0.6500\n",
            "Epoch 482/700\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.4752 - precision_6: 0.7574 - recall_6: 0.6486\n",
            "Epoch 483/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.4751 - precision_6: 0.7583 - recall_6: 0.6464\n",
            "Epoch 484/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.4749 - precision_6: 0.7562 - recall_6: 0.6532\n",
            "Epoch 485/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.4748 - precision_6: 0.7563 - recall_6: 0.6530\n",
            "Epoch 486/700\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4746 - precision_6: 0.7575 - recall_6: 0.6530\n",
            "Epoch 487/700\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.4745 - precision_6: 0.7579 - recall_6: 0.6494\n",
            "Epoch 488/700\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.4743 - precision_6: 0.7574 - recall_6: 0.6538\n",
            "Epoch 489/700\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.4742 - precision_6: 0.7584 - recall_6: 0.6486\n",
            "Epoch 490/700\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4741 - precision_6: 0.7582 - recall_6: 0.6498\n",
            "Epoch 491/700\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.4739 - precision_6: 0.7583 - recall_6: 0.6532\n",
            "Epoch 492/700\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.4738 - precision_6: 0.7590 - recall_6: 0.6506\n",
            "Epoch 493/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4736 - precision_6: 0.7580 - recall_6: 0.6526\n",
            "Epoch 494/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4735 - precision_6: 0.7590 - recall_6: 0.6520\n",
            "Epoch 495/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4733 - precision_6: 0.7587 - recall_6: 0.6522\n",
            "Epoch 496/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4732 - precision_6: 0.7579 - recall_6: 0.6550\n",
            "Epoch 497/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4731 - precision_6: 0.7569 - recall_6: 0.6568\n",
            "Epoch 498/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4729 - precision_6: 0.7573 - recall_6: 0.6554\n",
            "Epoch 499/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4728 - precision_6: 0.7577 - recall_6: 0.6556\n",
            "Epoch 500/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4726 - precision_6: 0.7585 - recall_6: 0.6566\n",
            "Epoch 501/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4725 - precision_6: 0.7581 - recall_6: 0.6556\n",
            "Epoch 502/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4724 - precision_6: 0.7580 - recall_6: 0.6534\n",
            "Epoch 503/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4722 - precision_6: 0.7584 - recall_6: 0.6592\n",
            "Epoch 504/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4721 - precision_6: 0.7580 - recall_6: 0.6554\n",
            "Epoch 505/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4719 - precision_6: 0.7579 - recall_6: 0.6530\n",
            "Epoch 506/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4718 - precision_6: 0.7575 - recall_6: 0.6528\n",
            "Epoch 507/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4716 - precision_6: 0.7580 - recall_6: 0.6526\n",
            "Epoch 508/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4715 - precision_6: 0.7579 - recall_6: 0.6530\n",
            "Epoch 509/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4714 - precision_6: 0.7581 - recall_6: 0.6518\n",
            "Epoch 510/700\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.4712 - precision_6: 0.7581 - recall_6: 0.6532\n",
            "Epoch 511/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4711 - precision_6: 0.7591 - recall_6: 0.6540\n",
            "Epoch 512/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4710 - precision_6: 0.7594 - recall_6: 0.6540\n",
            "Epoch 513/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4708 - precision_6: 0.7589 - recall_6: 0.6542\n",
            "Epoch 514/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4707 - precision_6: 0.7603 - recall_6: 0.6528\n",
            "Epoch 515/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4705 - precision_6: 0.7587 - recall_6: 0.6546\n",
            "Epoch 516/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4704 - precision_6: 0.7587 - recall_6: 0.6558\n",
            "Epoch 517/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4703 - precision_6: 0.7594 - recall_6: 0.6560\n",
            "Epoch 518/700\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.4701 - precision_6: 0.7582 - recall_6: 0.6572\n",
            "Epoch 519/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4700 - precision_6: 0.7590 - recall_6: 0.6562\n",
            "Epoch 520/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4699 - precision_6: 0.7608 - recall_6: 0.6546\n",
            "Epoch 521/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4697 - precision_6: 0.7604 - recall_6: 0.6550\n",
            "Epoch 522/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4696 - precision_6: 0.7598 - recall_6: 0.6542\n",
            "Epoch 523/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4694 - precision_6: 0.7595 - recall_6: 0.6564\n",
            "Epoch 524/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4693 - precision_6: 0.7601 - recall_6: 0.6552\n",
            "Epoch 525/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4692 - precision_6: 0.7610 - recall_6: 0.6528\n",
            "Epoch 526/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4690 - precision_6: 0.7610 - recall_6: 0.6548\n",
            "Epoch 527/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4689 - precision_6: 0.7610 - recall_6: 0.6534\n",
            "Epoch 528/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4688 - precision_6: 0.7611 - recall_6: 0.6530\n",
            "Epoch 529/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4686 - precision_6: 0.7607 - recall_6: 0.6548\n",
            "Epoch 530/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4685 - precision_6: 0.7629 - recall_6: 0.6512\n",
            "Epoch 531/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4684 - precision_6: 0.7614 - recall_6: 0.6530\n",
            "Epoch 532/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4682 - precision_6: 0.7625 - recall_6: 0.6532\n",
            "Epoch 533/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.4681 - precision_6: 0.7629 - recall_6: 0.6546\n",
            "Epoch 534/700\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.4680 - precision_6: 0.7609 - recall_6: 0.6586\n",
            "Epoch 535/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.4678 - precision_6: 0.7606 - recall_6: 0.6572\n",
            "Epoch 536/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.4677 - precision_6: 0.7605 - recall_6: 0.6604\n",
            "Epoch 537/700\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.4675 - precision_6: 0.7621 - recall_6: 0.6574\n",
            "Epoch 538/700\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.4674 - precision_6: 0.7618 - recall_6: 0.6574\n",
            "Epoch 539/700\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.4673 - precision_6: 0.7614 - recall_6: 0.6594\n",
            "Epoch 540/700\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.4671 - precision_6: 0.7618 - recall_6: 0.6582\n",
            "Epoch 541/700\n",
            "2/2 [==============================] - 1s 116ms/step - loss: 0.4670 - precision_6: 0.7615 - recall_6: 0.6582\n",
            "Epoch 542/700\n",
            "2/2 [==============================] - 1s 162ms/step - loss: 0.4669 - precision_6: 0.7613 - recall_6: 0.6588\n",
            "Epoch 543/700\n",
            "2/2 [==============================] - 1s 99ms/step - loss: 0.4668 - precision_6: 0.7612 - recall_6: 0.6616\n",
            "Epoch 544/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4666 - precision_6: 0.7616 - recall_6: 0.6614\n",
            "Epoch 545/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4665 - precision_6: 0.7616 - recall_6: 0.6576\n",
            "Epoch 546/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4663 - precision_6: 0.7626 - recall_6: 0.6622\n",
            "Epoch 547/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4662 - precision_6: 0.7627 - recall_6: 0.6594\n",
            "Epoch 548/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4661 - precision_6: 0.7628 - recall_6: 0.6578\n",
            "Epoch 549/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4659 - precision_6: 0.7634 - recall_6: 0.6562\n",
            "Epoch 550/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4658 - precision_6: 0.7635 - recall_6: 0.6578\n",
            "Epoch 551/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4657 - precision_6: 0.7633 - recall_6: 0.6590\n",
            "Epoch 552/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4655 - precision_6: 0.7638 - recall_6: 0.6578\n",
            "Epoch 553/700\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.4654 - precision_6: 0.7619 - recall_6: 0.6638\n",
            "Epoch 554/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4653 - precision_6: 0.7633 - recall_6: 0.6616\n",
            "Epoch 555/700\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.4652 - precision_6: 0.7636 - recall_6: 0.6588\n",
            "Epoch 556/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4650 - precision_6: 0.7651 - recall_6: 0.6546\n",
            "Epoch 557/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4649 - precision_6: 0.7647 - recall_6: 0.6550\n",
            "Epoch 558/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4648 - precision_6: 0.7643 - recall_6: 0.6552\n",
            "Epoch 559/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4646 - precision_6: 0.7645 - recall_6: 0.6582\n",
            "Epoch 560/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4645 - precision_6: 0.7644 - recall_6: 0.6600\n",
            "Epoch 561/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4644 - precision_6: 0.7631 - recall_6: 0.6624\n",
            "Epoch 562/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4642 - precision_6: 0.7640 - recall_6: 0.6616\n",
            "Epoch 563/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4641 - precision_6: 0.7655 - recall_6: 0.6576\n",
            "Epoch 564/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4640 - precision_6: 0.7650 - recall_6: 0.6594\n",
            "Epoch 565/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4638 - precision_6: 0.7650 - recall_6: 0.6600\n",
            "Epoch 566/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4637 - precision_6: 0.7646 - recall_6: 0.6634\n",
            "Epoch 567/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4636 - precision_6: 0.7643 - recall_6: 0.6640\n",
            "Epoch 568/700\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.4634 - precision_6: 0.7652 - recall_6: 0.6634\n",
            "Epoch 569/700\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.4633 - precision_6: 0.7651 - recall_6: 0.6638\n",
            "Epoch 570/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4632 - precision_6: 0.7646 - recall_6: 0.6652\n",
            "Epoch 571/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4631 - precision_6: 0.7648 - recall_6: 0.6654\n",
            "Epoch 572/700\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.4629 - precision_6: 0.7645 - recall_6: 0.6660\n",
            "Epoch 573/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4628 - precision_6: 0.7654 - recall_6: 0.6648\n",
            "Epoch 574/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4627 - precision_6: 0.7655 - recall_6: 0.6646\n",
            "Epoch 575/700\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.4626 - precision_6: 0.7648 - recall_6: 0.6654\n",
            "Epoch 576/700\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.4624 - precision_6: 0.7657 - recall_6: 0.6654\n",
            "Epoch 577/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.4623 - precision_6: 0.7660 - recall_6: 0.6614\n",
            "Epoch 578/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.4622 - precision_6: 0.7668 - recall_6: 0.6610\n",
            "Epoch 579/700\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.4620 - precision_6: 0.7672 - recall_6: 0.6618\n",
            "Epoch 580/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.4619 - precision_6: 0.7677 - recall_6: 0.6604\n",
            "Epoch 581/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4618 - precision_6: 0.7679 - recall_6: 0.6612\n",
            "Epoch 582/700\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.4617 - precision_6: 0.7668 - recall_6: 0.6648\n",
            "Epoch 583/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4615 - precision_6: 0.7681 - recall_6: 0.6638\n",
            "Epoch 584/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4614 - precision_6: 0.7679 - recall_6: 0.6636\n",
            "Epoch 585/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4613 - precision_6: 0.7678 - recall_6: 0.6632\n",
            "Epoch 586/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4611 - precision_6: 0.7669 - recall_6: 0.6626\n",
            "Epoch 587/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4610 - precision_6: 0.7674 - recall_6: 0.6644\n",
            "Epoch 588/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4609 - precision_6: 0.7672 - recall_6: 0.6630\n",
            "Epoch 589/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4608 - precision_6: 0.7665 - recall_6: 0.6644\n",
            "Epoch 590/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4606 - precision_6: 0.7683 - recall_6: 0.6630\n",
            "Epoch 591/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4605 - precision_6: 0.7688 - recall_6: 0.6618\n",
            "Epoch 592/700\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.4604 - precision_6: 0.7684 - recall_6: 0.6628\n",
            "Epoch 593/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4603 - precision_6: 0.7687 - recall_6: 0.6628\n",
            "Epoch 594/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4601 - precision_6: 0.7691 - recall_6: 0.6622\n",
            "Epoch 595/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4600 - precision_6: 0.7695 - recall_6: 0.6616\n",
            "Epoch 596/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4599 - precision_6: 0.7681 - recall_6: 0.6650\n",
            "Epoch 597/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4598 - precision_6: 0.7688 - recall_6: 0.6624\n",
            "Epoch 598/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4597 - precision_6: 0.7693 - recall_6: 0.6622\n",
            "Epoch 599/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4595 - precision_6: 0.7695 - recall_6: 0.6618\n",
            "Epoch 600/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4594 - precision_6: 0.7716 - recall_6: 0.6614\n",
            "Epoch 601/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4593 - precision_6: 0.7696 - recall_6: 0.6646\n",
            "Epoch 602/700\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.4591 - precision_6: 0.7697 - recall_6: 0.6652\n",
            "Epoch 603/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4590 - precision_6: 0.7677 - recall_6: 0.6670\n",
            "Epoch 604/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4589 - precision_6: 0.7688 - recall_6: 0.6656\n",
            "Epoch 605/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4587 - precision_6: 0.7679 - recall_6: 0.6684\n",
            "Epoch 606/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4586 - precision_6: 0.7674 - recall_6: 0.6696\n",
            "Epoch 607/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4585 - precision_6: 0.7687 - recall_6: 0.6674\n",
            "Epoch 608/700\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.4584 - precision_6: 0.7678 - recall_6: 0.6668\n",
            "Epoch 609/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4582 - precision_6: 0.7683 - recall_6: 0.6690\n",
            "Epoch 610/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4581 - precision_6: 0.7677 - recall_6: 0.6702\n",
            "Epoch 611/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4580 - precision_6: 0.7679 - recall_6: 0.6708\n",
            "Epoch 612/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4579 - precision_6: 0.7671 - recall_6: 0.6714\n",
            "Epoch 613/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4577 - precision_6: 0.7684 - recall_6: 0.6710\n",
            "Epoch 614/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4576 - precision_6: 0.7680 - recall_6: 0.6702\n",
            "Epoch 615/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4575 - precision_6: 0.7677 - recall_6: 0.6710\n",
            "Epoch 616/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4574 - precision_6: 0.7679 - recall_6: 0.6710\n",
            "Epoch 617/700\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.4572 - precision_6: 0.7692 - recall_6: 0.6680\n",
            "Epoch 618/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4571 - precision_6: 0.7699 - recall_6: 0.6670\n",
            "Epoch 619/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4570 - precision_6: 0.7699 - recall_6: 0.6680\n",
            "Epoch 620/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4568 - precision_6: 0.7696 - recall_6: 0.6686\n",
            "Epoch 621/700\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.4567 - precision_6: 0.7689 - recall_6: 0.6696\n",
            "Epoch 622/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4566 - precision_6: 0.7684 - recall_6: 0.6714\n",
            "Epoch 623/700\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.4565 - precision_6: 0.7696 - recall_6: 0.6706\n",
            "Epoch 624/700\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.4564 - precision_6: 0.7684 - recall_6: 0.6714\n",
            "Epoch 625/700\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.4562 - precision_6: 0.7688 - recall_6: 0.6716\n",
            "Epoch 626/700\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.4561 - precision_6: 0.7697 - recall_6: 0.6698\n",
            "Epoch 627/700\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.4560 - precision_6: 0.7707 - recall_6: 0.6688\n",
            "Epoch 628/700\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.4559 - precision_6: 0.7703 - recall_6: 0.6688\n",
            "Epoch 629/700\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.4557 - precision_6: 0.7711 - recall_6: 0.6670\n",
            "Epoch 630/700\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.4556 - precision_6: 0.7711 - recall_6: 0.6682\n",
            "Epoch 631/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4555 - precision_6: 0.7707 - recall_6: 0.6694\n",
            "Epoch 632/700\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.4554 - precision_6: 0.7708 - recall_6: 0.6692\n",
            "Epoch 633/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4552 - precision_6: 0.7719 - recall_6: 0.6672\n",
            "Epoch 634/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4551 - precision_6: 0.7721 - recall_6: 0.6694\n",
            "Epoch 635/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4550 - precision_6: 0.7721 - recall_6: 0.6674\n",
            "Epoch 636/700\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.4549 - precision_6: 0.7723 - recall_6: 0.6670\n",
            "Epoch 637/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4547 - precision_6: 0.7725 - recall_6: 0.6670\n",
            "Epoch 638/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4546 - precision_6: 0.7726 - recall_6: 0.6678\n",
            "Epoch 639/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4545 - precision_6: 0.7728 - recall_6: 0.6672\n",
            "Epoch 640/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4544 - precision_6: 0.7730 - recall_6: 0.6680\n",
            "Epoch 641/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4542 - precision_6: 0.7723 - recall_6: 0.6674\n",
            "Epoch 642/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4541 - precision_6: 0.7722 - recall_6: 0.6698\n",
            "Epoch 643/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4540 - precision_6: 0.7718 - recall_6: 0.6702\n",
            "Epoch 644/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4539 - precision_6: 0.7707 - recall_6: 0.6722\n",
            "Epoch 645/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4538 - precision_6: 0.7704 - recall_6: 0.6736\n",
            "Epoch 646/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4536 - precision_6: 0.7717 - recall_6: 0.6712\n",
            "Epoch 647/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4535 - precision_6: 0.7727 - recall_6: 0.6684\n",
            "Epoch 648/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4534 - precision_6: 0.7726 - recall_6: 0.6694\n",
            "Epoch 649/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4533 - precision_6: 0.7727 - recall_6: 0.6692\n",
            "Epoch 650/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4532 - precision_6: 0.7732 - recall_6: 0.6688\n",
            "Epoch 651/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4530 - precision_6: 0.7735 - recall_6: 0.6688\n",
            "Epoch 652/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4529 - precision_6: 0.7739 - recall_6: 0.6694\n",
            "Epoch 653/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4528 - precision_6: 0.7736 - recall_6: 0.6692\n",
            "Epoch 654/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4527 - precision_6: 0.7736 - recall_6: 0.6692\n",
            "Epoch 655/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4525 - precision_6: 0.7741 - recall_6: 0.6688\n",
            "Epoch 656/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4524 - precision_6: 0.7743 - recall_6: 0.6676\n",
            "Epoch 657/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4523 - precision_6: 0.7735 - recall_6: 0.6686\n",
            "Epoch 658/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4522 - precision_6: 0.7735 - recall_6: 0.6700\n",
            "Epoch 659/700\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4520 - precision_6: 0.7722 - recall_6: 0.6726\n",
            "Epoch 660/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4519 - precision_6: 0.7732 - recall_6: 0.6708\n",
            "Epoch 661/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4518 - precision_6: 0.7735 - recall_6: 0.6708\n",
            "Epoch 662/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4517 - precision_6: 0.7738 - recall_6: 0.6718\n",
            "Epoch 663/700\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.4516 - precision_6: 0.7740 - recall_6: 0.6714\n",
            "Epoch 664/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4514 - precision_6: 0.7740 - recall_6: 0.6718\n",
            "Epoch 665/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4513 - precision_6: 0.7736 - recall_6: 0.6732\n",
            "Epoch 666/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4512 - precision_6: 0.7727 - recall_6: 0.6732\n",
            "Epoch 667/700\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4511 - precision_6: 0.7735 - recall_6: 0.6720\n",
            "Epoch 668/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4510 - precision_6: 0.7742 - recall_6: 0.6722\n",
            "Epoch 669/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4508 - precision_6: 0.7743 - recall_6: 0.6724\n",
            "Epoch 670/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4507 - precision_6: 0.7741 - recall_6: 0.6750\n",
            "Epoch 671/700\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.4506 - precision_6: 0.7722 - recall_6: 0.6758\n",
            "Epoch 672/700\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.4505 - precision_6: 0.7737 - recall_6: 0.6730\n",
            "Epoch 673/700\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.4504 - precision_6: 0.7754 - recall_6: 0.6710\n",
            "Epoch 674/700\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.4502 - precision_6: 0.7753 - recall_6: 0.6714\n",
            "Epoch 675/700\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.4501 - precision_6: 0.7743 - recall_6: 0.6732\n",
            "Epoch 676/700\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.4500 - precision_6: 0.7748 - recall_6: 0.6728\n",
            "Epoch 677/700\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.4499 - precision_6: 0.7757 - recall_6: 0.6730\n",
            "Epoch 678/700\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.4497 - precision_6: 0.7751 - recall_6: 0.6750\n",
            "Epoch 679/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4496 - precision_6: 0.7746 - recall_6: 0.6758\n",
            "Epoch 680/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4495 - precision_6: 0.7742 - recall_6: 0.6768\n",
            "Epoch 681/700\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.4494 - precision_6: 0.7741 - recall_6: 0.6770\n",
            "Epoch 682/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4493 - precision_6: 0.7761 - recall_6: 0.6760\n",
            "Epoch 683/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4491 - precision_6: 0.7759 - recall_6: 0.6738\n",
            "Epoch 684/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4490 - precision_6: 0.7755 - recall_6: 0.6758\n",
            "Epoch 685/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4489 - precision_6: 0.7757 - recall_6: 0.6752\n",
            "Epoch 686/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4488 - precision_6: 0.7756 - recall_6: 0.6740\n",
            "Epoch 687/700\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.4486 - precision_6: 0.7759 - recall_6: 0.6760\n",
            "Epoch 688/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4485 - precision_6: 0.7760 - recall_6: 0.6762\n",
            "Epoch 689/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4484 - precision_6: 0.7759 - recall_6: 0.6752\n",
            "Epoch 690/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4483 - precision_6: 0.7762 - recall_6: 0.6762\n",
            "Epoch 691/700\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.4482 - precision_6: 0.7757 - recall_6: 0.6766\n",
            "Epoch 692/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4481 - precision_6: 0.7762 - recall_6: 0.6762\n",
            "Epoch 693/700\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.4479 - precision_6: 0.7765 - recall_6: 0.6766\n",
            "Epoch 694/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4478 - precision_6: 0.7751 - recall_6: 0.6790\n",
            "Epoch 695/700\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.4477 - precision_6: 0.7753 - recall_6: 0.6762\n",
            "Epoch 696/700\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.4476 - precision_6: 0.7761 - recall_6: 0.6768\n",
            "Epoch 697/700\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.4475 - precision_6: 0.7759 - recall_6: 0.6780\n",
            "Epoch 698/700\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.4474 - precision_6: 0.7738 - recall_6: 0.6808\n",
            "Epoch 699/700\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4472 - precision_6: 0.7751 - recall_6: 0.6804\n",
            "Epoch 700/700\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.4471 - precision_6: 0.7756 - recall_6: 0.6796\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c928037bd00>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_out = neur.predict(x_finaleval)\n",
        "output2 = outp[1][[0]]\n",
        "scal = MinMaxScaler()\n",
        "output2['predicted'] = scal.fit_transform(test_out)\n",
        "output2['actual'] = y_finaleval\n",
        "output2 = output2.drop(columns=[0])\n",
        "output2 = pd.merge(output2, maindataset[['index','tweet']], left_index=True, right_on=['index'])\n",
        "output2 = output2.sort_values(['predicted'], ascending=False)\n",
        "pd.options.display.max_colwidth = 150\n",
        "output2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "S_brCy4Lpsa_",
        "outputId": "aab83acf-1ac8-411f-af19-e19991640d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "419/419 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       predicted  actual  index  \\\n",
              "6098    1.000000       1   6189   \n",
              "5415    0.999650       1   5486   \n",
              "18974   0.999496       1  19136   \n",
              "12492   0.999495       1  12643   \n",
              "9353    0.999464       0   9490   \n",
              "...          ...     ...    ...   \n",
              "33420   0.000600       0  33641   \n",
              "35432   0.000500       0  35659   \n",
              "26392   0.000284       0  26611   \n",
              "42794   0.000268       0  43026   \n",
              "36791   0.000000       0  37020   \n",
              "\n",
              "                                                                                                                                           tweet  \n",
              "6098                                                                                             @itsjustmexo ur a cunt nd a wish a was a faggot  \n",
              "5415                                                                                                               @alesiahenderson wat a faggot  \n",
              "18974                                                   RT @iBeZo: Stupid fucking nigger LeBron. You flopping stupid jungle bunny monkey faggot.  \n",
              "12492                                Look at this little faggot.\\n\"@Kellz622: Tell her she's beautiful as much as you can. It'll make her smile\"  \n",
              "9353                                                                                                               Good day spent with my faggot  \n",
              "...                                                                                                                                          ...  \n",
              "33420  BUY MARIJUANA SEEDS: Revealed: The 10 Manchester bus lanes most likely to catch out drivers... https://t.co/MqRmtEb3cr #manchester #leeds  \n",
              "35432                                         Love this journal, lots of thoughtful articles and treasure! #tlchat #OZTL https://t.co/co8SCzzAp4  \n",
              "26392                     Just when you thought #TRFC had plumbed the depths of woeful cup draws...boom, Whitehawk away! https://t.co/mfxCOlLZ58  \n",
              "42794        When u want something so badly that everything else fades away and that one thing is your entire world... You know you will succeed  \n",
              "36791                                    Tap into your creative juices and find your happy place with Lisa Kamen: https://t.co/wpTueITUmq #coach  \n",
              "\n",
              "[13381 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98cd1032-856f-4a1f-9a17-342f72918db3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predicted</th>\n",
              "      <th>actual</th>\n",
              "      <th>index</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6098</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>6189</td>\n",
              "      <td>@itsjustmexo ur a cunt nd a wish a was a faggot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5415</th>\n",
              "      <td>0.999650</td>\n",
              "      <td>1</td>\n",
              "      <td>5486</td>\n",
              "      <td>@alesiahenderson wat a faggot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18974</th>\n",
              "      <td>0.999496</td>\n",
              "      <td>1</td>\n",
              "      <td>19136</td>\n",
              "      <td>RT @iBeZo: Stupid fucking nigger LeBron. You flopping stupid jungle bunny monkey faggot.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12492</th>\n",
              "      <td>0.999495</td>\n",
              "      <td>1</td>\n",
              "      <td>12643</td>\n",
              "      <td>Look at this little faggot.\\n\"@Kellz622: Tell her she's beautiful as much as you can. It'll make her smile\"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9353</th>\n",
              "      <td>0.999464</td>\n",
              "      <td>0</td>\n",
              "      <td>9490</td>\n",
              "      <td>Good day spent with my faggot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33420</th>\n",
              "      <td>0.000600</td>\n",
              "      <td>0</td>\n",
              "      <td>33641</td>\n",
              "      <td>BUY MARIJUANA SEEDS: Revealed: The 10 Manchester bus lanes most likely to catch out drivers... https://t.co/MqRmtEb3cr #manchester #leeds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35432</th>\n",
              "      <td>0.000500</td>\n",
              "      <td>0</td>\n",
              "      <td>35659</td>\n",
              "      <td>Love this journal, lots of thoughtful articles and treasure! #tlchat #OZTL https://t.co/co8SCzzAp4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26392</th>\n",
              "      <td>0.000284</td>\n",
              "      <td>0</td>\n",
              "      <td>26611</td>\n",
              "      <td>Just when you thought #TRFC had plumbed the depths of woeful cup draws...boom, Whitehawk away! https://t.co/mfxCOlLZ58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42794</th>\n",
              "      <td>0.000268</td>\n",
              "      <td>0</td>\n",
              "      <td>43026</td>\n",
              "      <td>When u want something so badly that everything else fades away and that one thing is your entire world... You know you will succeed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36791</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>37020</td>\n",
              "      <td>Tap into your creative juices and find your happy place with Lisa Kamen: https://t.co/wpTueITUmq #coach</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13381 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98cd1032-856f-4a1f-9a17-342f72918db3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98cd1032-856f-4a1f-9a17-342f72918db3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98cd1032-856f-4a1f-9a17-342f72918db3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-85377546-831e-402c-b4d3-fcfd7b1cfd92\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-85377546-831e-402c-b4d3-fcfd7b1cfd92')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-85377546-831e-402c-b4d3-fcfd7b1cfd92 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output2[\"predictedVal\"] = np.where(output2['predicted']>=0.5,1,0)\n",
        "print(classification_report(output2['actual'],output2[\"predictedVal\"] ))\n",
        "ConfusionMatrixDisplay.from_predictions(y_true=output2['actual'] ,y_pred=output2['predictedVal'] , cmap='PuBu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "RWRPDdRz4pr6",
        "outputId": "b58a57d9-f672-458a-e63c-52ab0ec60b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.83      0.88     11920\n",
            "           1       0.31      0.60      0.41      1461\n",
            "\n",
            "    accuracy                           0.81     13381\n",
            "   macro avg       0.62      0.72      0.64     13381\n",
            "weighted avg       0.87      0.81      0.83     13381\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7c9280648850>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}